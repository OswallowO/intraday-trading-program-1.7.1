#é€™å€‹ç‰ˆæœ¬æœ‰åˆªé™¤å¾ˆå¤šæœªå‘¼å«çš„å‡½æ•¸ï¼Œè«‹æ³¨æ„
#å·²å®Œæˆï¼šä¿®æ­£å›æ¸¬å‡½æ•¸é‚è¼¯ã€ä¸‹å–®ç„¡æ³•ç²å–è‚¡ç¥¨ä»£è™Ÿå•é¡Œã€ä¿®æ­£æ›´æ–°Kç·šæ•¸æ“šçš„bugã€‚
#ä¸‹ä¸€æ­¥ï¼šç”¨api.Contracts.Stocks[stock_code]å»å«å‡ºå•†å“æª”ï¼Œå»é™¤DayTrade.Yes: 'Yes'ä»¥å¤–çš„è‚¡ç¥¨ã€æ¼²åœé€²å ´æœ‰æ™‚å€™æœƒç„¡æ„ç¾©è§¸ç™¼ã€ç¢ºä¿ç¬¬ä¸€æ¬¡åŸ·è¡Œæ™‚å¯ç›´æ¥åŸ·è¡Œã€‚
import json
import os
import math
import subprocess
import sys
import time as time_module
import warnings
import msvcrt
import traceback
import shioaji_logic
import importlib
import csv
import threading
from datetime import datetime, time, timedelta, date
from concurrent.futures import ThreadPoolExecutor, as_completed

REQUIRED = [
    ("fugle_marketdata", "fugle-marketdata"),
    ("pandas",           "pandas"),
    ("yaml",             "pyyaml"),
    ("numpy",            "numpy"),
    ("colorama",         "colorama"),
    ("tabulate",         "tabulate"),
    ("openpyxl",         "openpyxl"),
    ("dateutil",         "python-dateutil"),
]

def ensure_packages(pkgs):
    """æª¢æŸ¥â†’ç¼ºå°‘å°± pip installâ†’æœ€å¾Œå†å‹•æ…‹ import å›ä¾†"""
    missing = []
    for mod, pkg in pkgs:
        try:
            importlib.import_module(mod)
        except ImportError:
            missing.append(pkg)

    if missing:
        print("é¦–æ¬¡åŸ·è¡Œåµæ¸¬åˆ°ä»¥ä¸‹å¥—ä»¶å°šæœªå®‰è£ï¼š", ", ".join(missing))
        for pkg in missing:
            subprocess.check_call(
                [sys.executable, "-m", "pip", "install", pkg]
            )
        # å®‰è£å®Œå†æŠŠå®ƒå€‘ import é€²ä¾†ï¼Œç¨‹å¼ä¸ç”¨é‡é–‹
        for mod, pkg in pkgs:
            globals()[mod] = importlib.import_module(mod)
    else:
        print("ğŸ‘  æ‰€æœ‰å¿…è¦å¥—ä»¶éƒ½å·²å®‰è£")

ensure_packages(REQUIRED)

import fugle_marketdata as fg
import pandas as pd
import yaml
import numpy as np
import colorama
import shioaji as sj
import touchprice as tp
import requests, bs4
import orjson
from tabulate import tabulate
from openpyxl.styles import PatternFill
from colorama import init, Fore, Style
from fugle_marketdata import RestClient
from bs4 import BeautifulSoup

colorama.init(autoreset=True)
warnings.filterwarnings("ignore", category=FutureWarning)

# å…¨åŸŸæ——æ¨™ï¼šæŒ‰ä¸‹ Q éµè§¸ç™¼å¹³å€‰é¸å–®
quit_flag = {"quit": False}

RED = Fore.RED
GREEN = Fore.GREEN
YELLOW = Fore.YELLOW
BLUE = Fore.BLUE
RESET = Style.RESET_ALL

pd.set_option('future.no_silent_downcasting', True)

def _crawl_tw_isin_table(mode: str):
    """
    mode = '2' â†’ ä¸Šå¸‚è‚¡ç¥¨
    mode = '4' â†’ ä¸Šæ«ƒè‚¡ç¥¨
    å›å‚³ [(ä»£è™Ÿ, ä¸­æ–‡å), ...]
    """

    url = f"https://isin.twse.com.tw/isin/C_public.jsp?strMode={mode}"
    r = requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
    r.encoding = "big5"                    # å®˜æ–¹ç¶²é ä»¥ Big5 ç·¨ç¢¼
    soup = bs4.BeautifulSoup(r.text, "lxml")
    rows = soup.select("table tr")[1:]     # ç¬¬ 0 åˆ—æ˜¯è¡¨é ­

    pairs = []
    for tr in rows:
        tds = tr.find_all("td")
        if not tds:
            continue
        raw = tds[0].text.strip()
        if raw[:4].isdigit():              # åªè¦å‰ 4 ç¢¼æ˜¯ç´”æ•¸å­—çš„è‚¡ç¥¨
            code = raw[:4]
            name = raw.split("\u3000", 1)[1] if "\u3000" in raw else raw[4:]
            pairs.append((code, name))
    return pairs

def fetch_twse_stock_codes(save_json=None, save_csv=None):
    """
    å–å¾—å°ç£ä¸Šå¸‚è‚¡ç¥¨ä»£è™Ÿèˆ‡ä¸­æ–‡åç¨±æ¸…å–®
    --------------------------------------------------
    Parameters
    ----------
    save_json : str | None
        è‹¥çµ¦æª”åï¼Œå°‡çµæœå­˜æˆ JSONï¼Œä¾‹å¦‚ "twse_stocks.json"
    save_csv  : str | None
        è‹¥çµ¦æª”åï¼Œå°‡çµæœå­˜æˆ CSVï¼Œä¾‹å¦‚ "twse_stocks.csv"

    Returns
    -------
    List[Tuple[str,str]]
        [('1101', 'å°æ³¥'), ('1102', 'äºæ³¥'), ...]
    """
    url     = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
    headers = {"User-Agent": "Mozilla/5.0"}

    res = requests.get(url, headers=headers, timeout=10)
    # ç¶²é æ¡ Bigâ€‘5ï¼Œæ‰‹å‹•æŒ‡å®šç·¨ç¢¼é¿å…äº‚ç¢¼
    res.encoding = "big5"

    soup = BeautifulSoup(res.text, "lxml")
    rows = soup.select("table tr")[1:]          # è·³éè¡¨é ­

    stocks = []
    for r in rows:
        cols = [c.text.strip() for c in r.find_all("td")]
        if not cols:
            continue
        code_name = cols[0]                     # ä¾‹ï¼šã€Œ1101ã€€å°æ³¥ã€
        if len(code_name) >= 4 and code_name[:4].isdigit():
            code = code_name[:4]
            # ä»¥ã€Œå…¨å½¢ç©ºæ ¼ã€åŠƒåˆ†å–ä¸­æ–‡åç¨±ï¼›è‹¥åˆ‡ä¸åˆ°å°±ç›´æ¥å–å‰©é¤˜å­—ä¸²
            name = code_name.split("\u3000", 1)[1] if "\u3000" in code_name else code_name[4:]
            stocks.append((code, name))

    # ----------- (é¸ç”¨) å­˜æª” -----------
    if save_json:
        with open(save_json, "w", encoding="utf-8") as f:
            json.dump(stocks, f, ensure_ascii=False, indent=2)
    if save_csv:
        with open(save_csv, "w", encoding="utf-8-sig", newline="") as f:
            w = csv.writer(f)
            w.writerow(["Code", "Name"])
            w.writerows(stocks)

    return stocks

STOCK_NAME_MAP = {}      # å…¨åŸŸå­—å…¸ { "1101": "å°æ³¥", ... }

def load_twse_name_map(json_path="twse_stocks_all.json"):
    global STOCK_NAME_MAP
    if STOCK_NAME_MAP:          # å·²ç¶“è¼‰éå°±ç•¥é
        return

    try:
        # 1) æœ¬åœ°å¿«å–å­˜åœ¨å°±ç›´æ¥è®€
        if os.path.exists(json_path):
            with open(json_path, "r", encoding="utf-8") as f:
                STOCK_NAME_MAP = json.load(f)
            return

        # 2) å¦å‰‡åŒæ™‚æŠ“ä¸Šå¸‚(2) + ä¸Šæ«ƒ(4)ï¼Œä½µå…¥å­—å…¸
        listed_pairs  = _crawl_tw_isin_table("2")   # ä¸Šå¸‚
        otc_pairs     = _crawl_tw_isin_table("4")   # ä¸Šæ«ƒ
        STOCK_NAME_MAP = {c: n for c, n in listed_pairs + otc_pairs}

        # 3) å¯«é€²å¿«å–æª”
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(STOCK_NAME_MAP, f, ensure_ascii=False, indent=2)

    except Exception as e:
        print(f"è¼‰å…¥è‚¡ç¥¨ä¸­æ–‡åç¨±å¤±æ•—ï¼š{e}")
        STOCK_NAME_MAP = {}

def get_stock_name(code):
    """çµ¦å®š 4 ç¢¼è‚¡ç¥¨ä»£è™Ÿï¼Œå›å‚³ä¸­æ–‡åç¨±ï¼›æ‰¾ä¸åˆ°å°±å›ç©ºå­—ä¸²"""
    return STOCK_NAME_MAP.get(code, "")

load_twse_name_map()
'''
# æ¸¬è©¦è‚¡ç¥¨ä»£è™Ÿæ˜¯å¦èƒ½é€£çµåˆ°ä¸­æ–‡åç¨±
print(get_stock_name("2330"))   # å°ç©é›»  (ä¸Šå¸‚)
print(get_stock_name("5483"))   # ä¸­ç¾æ™¶  (ä¸Šæ«ƒ)
'''

def init_fugle_client():
    try:
        config = load_config("config.yaml")
        client = RestClient(api_key=config['api_key'])
        print("=" * 50)
        print("å¾ config.yaml è¼‰å…¥ API é‡‘é‘°")
        print("=" * 50)
        return client, config['api_key']
    except FileNotFoundError:
        print("éŒ¯èª¤ï¼šconfig.yaml æ–‡ä»¶ä¸å­˜åœ¨ã€‚")
        sys.exit(1)
    except KeyError:
        print("éŒ¯èª¤ï¼šconfig.yaml ä¸­ç¼ºå°‘ 'api_key'ã€‚")
        sys.exit(1)
    except Exception as e:
        print(f"åˆå§‹åŒ–å¯ŒæœAPIå®¢æˆ¶ç«¯æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        sys.exit(1)

def load_config(config_file):
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        print(f"éŒ¯èª¤ï¼šç„¡æ³•æ‰¾åˆ° {config_file} æ–‡ä»¶ã€‚")
        sys.exit(1)
    except yaml.YAMLError as e:
        print(f"éŒ¯èª¤ï¼šè®€å– {config_file} æ–‡ä»¶æ™‚ç™¼ç”Ÿ YAML éŒ¯èª¤ï¼š{e}")
        sys.exit(1)

def calculate_5min_pct_increase_and_highest(intraday_df):
    """
    ä¿®æ”¹å¾Œçš„è¨ˆç®—æ–¹å¼ï¼š
    1. ç¬¬ä¸€æ ¹Kæ£’ï¼ˆä¾‹å¦‚ 09:00ï¼‰çš„ 5min_pct_increase å›ºå®šç‚º 0ã€‚
    2. ç¬¬äºŒåˆ°ç¬¬å››æ ¹Kæ£’ï¼ˆä¾‹å¦‚ 09:01~09:03ï¼‰ï¼šå–å¾ç¬¬ä¸€æ ¹åˆ°ç•¶å‰æ‰€æœ‰Kæ£’çš„ close å€¼ï¼Œ
         å¦‚æœæœ€å¾Œä¸€æ ¹çš„ close >= ç¬¬ä¸€æ ¹çš„ closeï¼ˆä¸Šå‡è¶¨å‹¢ï¼‰ï¼Œå…¬å¼ç‚º
              (æœ€å¤§close - æœ€å°close) * 100 / æœ€å°close
         å¦å‰‡ï¼ˆä¸‹é™è¶¨å‹¢ï¼‰ï¼Œå…¬å¼ç‚º
              (æœ€å°close - æœ€å¤§close) * 100 / æœ€å¤§close
    3. å¾ç¬¬äº”æ ¹Kæ£’ï¼ˆ9:04ä»¥å¾Œï¼‰é–‹å§‹ï¼Œå–æœ€è¿‘5æ ¹Kæ£’çš„ close å€¼ï¼ŒæŒ‰ä¸Šè¿°ç›¸åŒæ–¹å¼è¨ˆç®—ã€‚
    
    åŒæ™‚ï¼Œæ¯æ ¹Kæ£’çš„ highest è¨­ç‚ºå¾é–‹ç›¤åˆ°ç•¶å‰çš„æœ€é«˜ high å€¼ã€‚
    
    å‚³å…¥çš„ intraday_df å¿…é ˆåŒ…å« 'time', 'close', 'high' æ¬„ä½ï¼Œä¸”å·²æŒ‰æ™‚é–“æ’åºã€‚
    """
    # ä¿è­‰ä¾æ™‚é–“æ’åº
    intraday_df = intraday_df.sort_values(by='time').reset_index(drop=True)

    pct_increases = []
    highest_vals = []
    current_high = 0.0

    for idx, row in intraday_df.iterrows():
        try:
            close_val = float(row['close'])
        except Exception:
            close_val = 0.0
        try:
            high_val = float(row.get('high', 0.0))
        except Exception:
            high_val = close_val
        
        # ç´¯è¨ˆç•¶å‰æœ€é«˜ high å€¼
        current_high = max(current_high, high_val)
        highest_vals.append(current_high)

        if idx == 0:
            # ç¬¬ä¸€æ ¹Kæ£’ï¼šé è¨­ç‚º 0
            pct_increases.append(0.0)
        else:
            # æ±ºå®šå–å¹¾æ ¹Kæ£’ï¼šè‹¥ä¸è¶³5æ ¹å‰‡å– idx+1 æ ¹ï¼›è‹¥è¶³å¤ å‰‡å–æœ€è¿‘5æ ¹ï¼ˆidx-4 è‡³ idxï¼‰
            if idx < 4:
                start_idx = 0
            else:
                start_idx = idx - 4
            window = intraday_df.loc[start_idx: idx, 'close']
            try:
                close_values = window.astype(float).tolist()
            except Exception:
                close_values = []
            if len(close_values) < 2:
                pct_increases.append(0.0)
            else:
                first_close = close_values[0]
                last_close = close_values[-1]
                max_close = max(close_values)
                min_close = min(close_values)
                # æ ¹æ“šè¶¨å‹¢è¨ˆç®—ï¼šè‹¥æœ€å¾Œå€¼å¤§æ–¼ç­‰æ–¼ç¬¬ä¸€å€¼ï¼Œè¦–ç‚ºä¸Šå‡è¶¨å‹¢ï¼›å¦å‰‡ç‚ºä¸‹é™è¶¨å‹¢
                if last_close >= first_close:
                    # ä¸Šå‡è¶¨å‹¢ï¼šå…¬å¼ (æœ€å¤§ - æœ€å°)*100 / æœ€å°
                    pct = (max_close - min_close) * 100 / min_close if min_close != 0 else 0.0
                else:
                    # ä¸‹é™è¶¨å‹¢ï¼šå…¬å¼ (æœ€å° - æœ€å¤§)*100 / æœ€å¤§ï¼Œçµæœç‚ºè² å€¼
                    pct = (min_close - max_close) * 100 / max_close if max_close != 0 else 0.0
                pct_increases.append(pct)
    
    intraday_df['5min_pct_increase'] = pct_increases
    intraday_df['highest'] = highest_vals
    return intraday_df

def fetch_intraday_data(client, symbol, trading_day, yesterday_close_price, start_time=None, end_time=None):
    try:
        symbol = str(symbol).strip()
        if not symbol:
            print(f"âŒ ç„¡æ•ˆçš„ symbol: {symbol}")
            return pd.DataFrame()

        # è™•ç† trading_day åƒæ•¸
        if isinstance(trading_day, str):
            trading_day_date = datetime.strptime(trading_day, '%Y-%m-%d').date()
        elif isinstance(trading_day, datetime):
            trading_day_date = trading_day.date()
        elif isinstance(trading_day, date):
            trading_day_date = trading_day
        else:
            print(f"âŒ ç„¡æ•ˆ trading_day é¡å‹ï¼š{type(trading_day)}ï¼Œå€¼ï¼š{trading_day}")
            return pd.DataFrame()

        # è¨ˆç®—çµæŸæ™‚é–“
        today = datetime.now().date()
        if trading_day_date < today:
            end_time_str = "13:30"
        else:
            now = datetime.now()
            market_end = now.replace(hour=13, minute=30, second=0, microsecond=0)
            end_time_str = "13:30" if now > market_end else (now - timedelta(minutes=1)).replace(second=0, microsecond=0).strftime('%H:%M')

        _from = datetime.strptime(f"{trading_day} {start_time or '09:00'}", "%Y-%m-%d %H:%M")
        to = datetime.strptime(f"{trading_day} {end_time or end_time_str}", "%Y-%m-%d %H:%M")

        candles_rsp = client.stock.intraday.candles(
            symbol=symbol, timeframe='1',
            _from=_from.isoformat(), to=to.isoformat()
        )

        if not candles_rsp or not candles_rsp.get('data'):
            print(f"âš ï¸ API ç„¡å›å‚³è³‡æ–™ï¼š{candles_rsp}")
            return pd.DataFrame()

        candles_df = pd.DataFrame(candles_rsp['data'])
        if 'volume' not in candles_df.columns:
            print(f"âš ï¸ volume æ¬„ä½ä¸å­˜åœ¨ï¼å¯¦éš›æ¬„ä½ï¼š{candles_df.columns.tolist()}")
            return pd.DataFrame()

        candles_df['volume'] = pd.to_numeric(candles_df['volume'], errors='coerce')
        candles_df['datetime'] = pd.to_datetime(candles_df['date'], errors='coerce').dt.tz_localize(None).dt.floor('min')
        candles_df.set_index('datetime', inplace=True)

        original_df = candles_df.reset_index()[['datetime', 'volume']].rename(columns={'volume': 'orig_volume'})

        full_idx = pd.date_range(start=_from, end=to, freq='1min')
        candles_df = candles_df.reindex(full_idx)

        candles_df.reset_index(inplace=True)
        candles_df.rename(columns={'index': 'datetime'}, inplace=True)
        candles_df['date'] = candles_df['datetime'].dt.strftime('%Y-%m-%d')
        candles_df['time'] = candles_df['datetime'].dt.strftime('%H:%M:%S')

        candles_df = pd.merge(candles_df, original_df, how='left', on='datetime')
        candles_df['was_filled'] = candles_df['orig_volume'].isna()

        # âœ… ä½¿ç”¨å‘é‡åŒ–è£œå€¼å–ä»£ iterrowsï¼Œæ•ˆç‡å¤§å¹…æå‡
        filled = candles_df['was_filled'].to_numpy()
        close = candles_df['close'].to_numpy()
        fallback_close = np.empty_like(close)

        last_valid = yesterday_close_price
        for i in range(len(close)):
            if filled[i]:
                fallback_close[i] = last_valid
            else:
                if not pd.isna(close[i]):
                    last_valid = close[i]
                fallback_close[i] = close[i]

        for col in ['open', 'high', 'low', 'close']:
            values = candles_df[col].to_numpy()
            values[filled] = fallback_close[filled]
            candles_df[col] = values

        candles_df['volume'] = candles_df['orig_volume'].fillna(0)

        candles_df['symbol'] = symbol
        candles_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹'] = yesterday_close_price
        candles_df['æ¼²åœåƒ¹'] = truncate_to_two_decimals(calculate_limit_up_price(yesterday_close_price))
        candles_df[['symbol', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹']] = candles_df[['symbol', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹']].ffill().bfill()
        candles_df['rise'] = (candles_df['close'] - candles_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹']) / candles_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹'] * 100
        candles_df['highest'] = candles_df['high'].cummax()

        return candles_df[[ 'symbol', 'date', 'time', 'open', 'high', 'low',
                            'close', 'volume', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹', 'rise', 'highest' ]]

    except Exception as e:
        print(f"âŒ ç™¼ç”Ÿä¾‹å¤–éŒ¯èª¤ï¼š{e}")
        traceback.print_exc()
        return pd.DataFrame()



def get_recent_trading_day():
    today = datetime.now().date()
    current_time = datetime.now().time()
    market_close_time = datetime.strptime("13:30", "%H:%M").time()
    market_open_time = datetime.strptime("09:00", "%H:%M").time()
    
    def last_friday(date):
        while date.weekday() != 4:
            date -= timedelta(days=1)
        return date

    weekday = today.weekday()
    
    if weekday == 0:
        if current_time >= market_close_time:
            trading_day = today
        else:
            trading_day = last_friday(today)
    elif weekday == 5:
        trading_day = last_friday(today)
    elif weekday == 6:
        trading_day = last_friday(today)
    else:
        if current_time >= market_close_time:
            trading_day = today
        elif current_time < market_open_time:
            trading_day = today - timedelta(days=1)
            if trading_day.weekday() == 0:
                trading_day = last_friday(trading_day)
        else:
            trading_day = today
    return trading_day

def fetch_daily_kline_data(client, symbol, days=2):
    end_date = get_recent_trading_day()
    start_date = end_date - timedelta(days=days)
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')

    print(f"æ­£åœ¨å–å¾— {symbol} å¾ {start_date_str} åˆ° {end_date_str} çš„æ—¥Kæ•¸æ“š...")

    try:
        data = client.stock.historical.candles(symbol=symbol, from_=start_date_str, to=end_date_str)
        if 'data' in data and data['data']:
            daily_kline_df = pd.DataFrame(data['data'])
            return daily_kline_df
        else:
            print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼šAPI å›æ‡‰ä¸­ä¸åŒ…å« 'data' æ¬„ä½æˆ– 'data' ç‚ºç©º")
            return pd.DataFrame()
    except Exception as e:
        print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼š{e}")
        return pd.DataFrame()

def save_matrix_dict(matrix_dict):
    with open('matrix_dict_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(matrix_dict, f, indent=4, ensure_ascii=False)

def load_matrix_dict_analysis():
    if os.path.exists('matrix_dict_analysis.json'):
        with open('matrix_dict_analysis.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        print("matrix_dict_analysis.json æ–‡ä»¶ä¸å­˜åœ¨ã€‚")
        return {}

def save_nb_matrix_dict(nb_matrix_dict):
    with open('nb_matrix_dict.json', 'w', encoding='utf-8') as f:
        json.dump(nb_matrix_dict, f, indent=4, ensure_ascii=False, default=str)

def initialize_stock_data(symbols_to_analyze, daily_kline_data, intraday_kline_data):
    stock_data_collection = {}
    for symbol in symbols_to_analyze:
        if symbol not in daily_kline_data or symbol not in intraday_kline_data:
            print(f"è‚¡ç¥¨ä»£è™Ÿ {symbol} çš„æ—¥ K ç·šæˆ–ä¸€åˆ† K ç·šè³‡æ–™ç¼ºå¤±ï¼Œè·³éã€‚")
            continue
        daily_kline_df = pd.DataFrame(daily_kline_data[symbol])
        intraday_data = pd.DataFrame(intraday_kline_data[symbol])
        if intraday_data.empty:
            print(f"è‚¡ç¥¨ä»£è™Ÿ {symbol} çš„æ—¥å…§æ•¸æ“šç‚ºç©ºï¼Œè·³éã€‚")
            continue
        complete_df = ensure_continuous_time_series(intraday_data)
        complete_df = complete_df.drop(columns=['average'], errors='ignore')
        stock_data_collection[symbol] = complete_df
    return stock_data_collection

def process_group_data(stock_data_collection, wait_minutes, hold_minutes,
                       matrix_dict_analysis, verbose=True):
    """
    === å›æ¸¬å‡½æ•¸ (Back-test)  ===
    - åŒæ­¥ process_live_trading_logic çš„å››å¤§é‚è¼¯ï¼š
      1. æ‹‰é«˜è§¸ç™¼ï¼š5-min æ¼²å¹… â‰¥ 2% ä¸”æˆäº¤é‡ > 1.5Ã—(09:00-09:02 å¹³å‡é‡)
      2. è¿½è¹¤æ¸…å–®åŠ å…¥é–€æª»ï¼š5-min æ¼²å¹… â‰¥ 1.5%
      3. æ¼²åœè§¸ç™¼ï¼šhigh == æ¼²åœåƒ¹ ä¸” (å‰ä¸€æ ¹ high < æ¼²åœåƒ¹ï¼Œ09:00 ä¾‹å¤–)
      4. ç­‰å¾…æœŸæ»¿å¾Œçš„ eligible ç¯©é¸èˆ‡é€²å ´ã€åœæé‚è¼¯
    """

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0-A. æœ¬åœ°æ——æ¨™åˆå§‹åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    in_position         = False
    has_exited          = False
    current_position    = None
    stop_loss_triggered = False
    final_check_active  = False        # å›æ¸¬ç‰ˆä»ä¿ç•™ä½†ç›®å‰æœªç”¨
    final_check_count   = 0            # ã€ƒ
    hold_time           = 0

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0-B. éœ€è¦çš„å…¨åŸŸè¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
    global capital_per_stock, transaction_fee, transaction_discount, trading_tax
    global price_gap_below_50, price_gap_50_to_100, price_gap_100_to_500
    global price_gap_500_to_1000, price_gap_above_1000
    global allow_reentry_after_stop_loss
    # --------------------------------------------------------------

    # ---------- 0-C. é–‹ç›¤å‰ä¸‰åˆ†é˜å¹³å‡é‡ ---------- #
    FIRST3_AVG_VOL: dict[str, float] = {}
    for sym, df in stock_data_collection.items():
        first3 = df[df['time'].astype(str).isin(['09:00:00', '09:01:00', '09:02:00'])]
        FIRST3_AVG_VOL[sym] = first3['volume'].mean() if not first3.empty else 0

    # ---------- 0-D. å…¶ä»–ç‹€æ…‹è®Šæ•¸ ---------- #
    message_log: list[tuple[str, str]] = []
    tracking_stocks: set[str] = set()
    leader                      = None
    leader_peak_rise            = None
    leader_rise_before_decline  = None
    in_waiting_period           = False
    waiting_time                = 0
    pull_up_entry               = False
    limit_up_entry              = False
    first_condition_one_time    = None

    # ---------- 0-E. çµ„ merge DataFrame ---------- #
    merged_df = None
    req_cols = ['time', 'rise', 'high', 'æ¼²åœåƒ¹',
                'close', '5min_pct_increase', 'volume']
    for sym, df in stock_data_collection.items():
        if not all(c in df.columns for c in req_cols):
            continue
        tmp = df[req_cols].copy()
        tmp = tmp.rename(columns={
            'rise':               f'rise_{sym}',
            'high':               f'high_{sym}',
            'æ¼²åœåƒ¹':             f'limit_up_price_{sym}',
            'close':              f'close_{sym}',
            '5min_pct_increase':  f'5min_pct_increase_{sym}',
            'volume':             f'volume_{sym}'
        })
        merged_df = tmp if merged_df is None else pd.merge(
            merged_df, tmp, on='time', how='outer')

    if merged_df is None or merged_df.empty:
        print("ç„¡æœ‰æ•ˆè³‡æ–™å¯å›æ¸¬")
        return None, None
    merged_df.sort_values('time', inplace=True, ignore_index=True)

    # â•â•â•â•â•â•â•â•â•â•â• 1. é€åˆ†é˜ä¸»è¿´åœˆ â•â•â•â•â•â•â•â•â•â•â• #
    total_profit = total_profit_rate = total_trades = 0

    for _, row in merged_df.iterrows():
        current_time     = row['time']
        current_time_str = current_time.strftime('%H:%M:%S')

        # â”€â”€ 1-1. æŒå€‰æœŸé–“ï¼šå¼·åˆ¶ / æ™‚é–“å¹³å€‰ / æ¢ä»¶åœæ â”€â”€ #
        if in_position and not has_exited:
            hold_time += 1

            # a) 13:30 å¼·åˆ¶
            if current_time_str == '13:30:00':
                profit, rate = exit_trade(
                    stock_data_collection[current_position['symbol']],
                    current_position['shares'],
                    current_position['entry_price'],
                    current_position['sell_cost'],
                    current_position['entry_fee'],
                    current_position['tax'],
                    message_log,
                    current_time, hold_time,
                    current_position['entry_time'],
                    use_f_exit=True
                )
                if profit is not None:
                    total_trades += 1
                    total_profit += profit
                    total_profit_rate += rate
                in_position = False
                has_exited  = True
                current_position = None
                continue

            # b) æŒæœ‰åˆ†é˜åˆ°æœŸ
            if hold_minutes is not None and hold_time >= hold_minutes:
                profit, rate = exit_trade(
                    stock_data_collection[current_position['symbol']],
                    current_position['shares'],
                    current_position['entry_price'],
                    current_position['sell_cost'],
                    current_position['entry_fee'],
                    current_position['tax'],
                    message_log,
                    current_time, hold_time,
                    current_position['entry_time']
                )
                if profit is not None:
                    total_trades += 1
                    total_profit += profit
                    total_profit_rate += rate
                in_position = False
                has_exited  = True
                continue

            # c) åœææ¢ä»¶ä¸‰
            sel_df  = stock_data_collection[current_position['symbol']]
            now_row = sel_df[sel_df['time'] == current_time]
            if not now_row.empty:
                h_now = truncate_to_two_decimals(now_row.iloc[0]['high'])
                thresh = truncate_to_two_decimals(
                    current_position['stop_loss_threshold'])
                if h_now >= thresh:
                    exit_price = thresh
                    exit_cost  = current_position['shares'] * exit_price * 1000
                    exit_fee   = int(exit_cost * (transaction_fee*0.01) *
                                     (transaction_discount*0.01))
                    profit = (current_position['sell_cost'] - exit_cost
                              - current_position['entry_fee'] - exit_fee
                              - current_position['tax'])
                    rate = (profit * 100) / (current_position['sell_cost']
                                              - current_position['entry_fee']
                                              - exit_fee)
                    message_log.append(
                        (current_time_str,
                         f"{Fore.RED}åœæè§¸ç™¼ï¼Œåˆ©æ½¤ {int(profit)} å…ƒ "
                         f"({rate:.2f}%){Style.RESET_ALL}")
                    )
                    total_trades += 1
                    total_profit += profit
                    total_profit_rate += rate
                    in_position = False
                    has_exited  = True
                    current_position = None
                    stop_loss_triggered = True
                    if not allow_reentry_after_stop_loss:
                        break
            continue  # æŒå€‰æ™‚ä¸å†æª¢æŸ¥æ–°è§¸ç™¼

        # â”€â”€ 1-2. æª¢æŸ¥è§¸ç™¼ (æ‹‰é«˜/æ¼²åœ) â”€â”€ #
        trigger_list = []
        for sym in stock_data_collection.keys():
            pct  = row.get(f'5min_pct_increase_{sym}')
            vol  = row.get(f'volume_{sym}')
            high = row.get(f'high_{sym}')
            lup  = row.get(f'limit_up_price_{sym}')
            avgv = FIRST3_AVG_VOL.get(sym, 0)

            # æ¼²åœ
            hit_limit = False
            if high is not None and lup is not None and high == lup:
                if current_time_str == '09:00:00':
                    hit_limit = True
                else:
                    prev_time = (datetime.combine(date.today(), current_time)
                                 - timedelta(minutes=1)).time()
                    prev_high = stock_data_collection[sym].loc[
                        stock_data_collection[sym]['time'] == prev_time,
                        'high']
                    if prev_high.empty or prev_high.iloc[0] < lup:
                        hit_limit = True
            if hit_limit:
                trigger_list.append({'symbol': sym, 'condition': 'limit_up'})
                continue

            # æ‹‰é«˜
            if (pct is not None and pct >= 2
               and vol is not None and avgv and vol > 1.5*avgv):
                trigger_list.append({'symbol': sym, 'condition': 'pull_up'})

        # â”€â”€ 1-3. è™•ç†è§¸ç™¼çµæœ â†’ æ›´æ–° tracking / leader / waiting â”€â”€ #
        for item in trigger_list:
            sym  = item['symbol']
            cond = item['condition']
            if cond == 'limit_up':
                tracking_stocks.clear()
                tracking_stocks.add(sym)
                leader = sym
                in_waiting_period = True
                waiting_time = 1
                pull_up_entry  = False
                limit_up_entry = True
                first_condition_one_time = datetime.combine(date.today(), current_time)
                if verbose:
                    message_log.append(
                        (current_time_str,
                         f"{Fore.CYAN}{sym} æ¼²åœè§¸ç™¼ï¼Œé–‹å§‹ç­‰å¾…{Style.RESET_ALL}"))
            else:  # pull_up
                if not pull_up_entry:
                    pull_up_entry = True
                    limit_up_entry = False
                    tracking_stocks.clear()
                    first_condition_one_time = datetime.combine(date.today(), current_time)
                tracking_stocks.add(sym)
                if verbose:
                    message_log.append(
                        (current_time_str,
                         f"{sym} æ‹‰é«˜è§¸ç™¼ï¼ŒåŠ å…¥è¿½è¹¤"))

        # è¿½è¹¤æ¸…å–®æ“´å……é–€æª» 1.5%
        if pull_up_entry:
            for sym in stock_data_collection.keys():
                if sym in tracking_stocks:
                    continue
                pct = row.get(f'5min_pct_increase_{sym}')
                if pct is not None and pct >= 1.5:
                    tracking_stocks.add(sym)

        # â”€â”€ 1-4. é ˜æ¼²é¸æ“‡èˆ‡åè½‰åµæ¸¬ â”€â”€ #
        if pull_up_entry and tracking_stocks:
            # é¸æ“‡ rise æœ€å¤§è€…
            max_sym, max_rise = None, None
            for sym in tracking_stocks:
                r = row.get(f'rise_{sym}')
                if r is not None and (max_rise is None or r > max_rise):
                    max_rise, max_sym = r, sym
            if leader != max_sym:
                if leader and verbose:
                    message_log.append(
                        (current_time_str,
                         f"é ˜æ¼²æ›¿æ›ï¼š{leader} â†’ {max_sym}"))
                leader = max_sym
                leader_peak_rise = max_rise
            # åè½‰ â†’ é€²å…¥ç­‰å¾…
            if leader:
                h_now = row.get(f'high_{leader}')
                prev_time = (datetime.combine(date.today(), current_time)
                             - timedelta(minutes=1)).time()
                prev_row = stock_data_collection[leader][
                    stock_data_collection[leader]['time'] == prev_time]
                if not prev_row.empty:
                    h_prev = prev_row.iloc[0]['high']
                    if h_now <= h_prev and not in_waiting_period:
                        in_waiting_period = True
                        waiting_time = 1
                        leader_rise_before_decline = max_rise
                        if verbose:
                            message_log.append(
                                (current_time_str,
                                 f"é ˜æ¼² {leader} åè½‰ï¼Œé–‹å§‹ç­‰å¾…"))

        # â”€â”€ 1-5. ç­‰å¾…æ™‚é–“è¨ˆæ•¸ & å®Œæˆå¾Œç¯©é¸ eligible â”€â”€ #
        if in_waiting_period:
            if waiting_time >= wait_minutes:
                in_waiting_period = False
                waiting_time = 0

                # helper for eligible
                def _vol_break(sym, join_time):
                    df   = stock_data_collection[sym]
                    avgv = FIRST3_AVG_VOL.get(sym, 0)
                    later = df[df['time'] >= join_time.time()]
                    return (later['volume'] >= 1.5*avgv).any()

                def _rise_peak_flat(sym, join_time):
                    df  = stock_data_collection[sym]
                    sub = df[df['time'] >= join_time.time()]
                    if sub.empty:
                        return False
                    pkidx = sub['rise'].idxmax()
                    pkval = sub.loc[pkidx, 'rise']
                    return (sub[sub.index > pkidx]['rise'] <= pkval).all()

                eligible = []
                for sym in tracking_stocks:
                    if sym == leader:
                        continue
                    if not _vol_break(sym, first_condition_one_time):
                        continue
                    if not _rise_peak_flat(sym, first_condition_one_time):
                        continue
                    rise_now = row.get(f'rise_{sym}')
                    if rise_now is None or not (-2 <= rise_now <= 6):
                        continue
                    price_now = row.get(f'close_{sym}')
                    if price_now is None or price_now > capital_per_stock*1.5:
                        continue
                    row_sym = stock_data_collection[sym].loc[
                        stock_data_collection[sym]['time'] == current_time].iloc[0]
                    eligible.append({'symbol': sym, 'rise': rise_now, 'row': row_sym})

                if not eligible:
                    # æµç¨‹é‡ç½®
                    pull_up_entry = limit_up_entry = False
                    tracking_stocks.clear()
                    if verbose:
                        message_log.append(
                            (current_time_str,
                             "ç­‰å¾…çµæŸç„¡ç¬¦åˆè‚¡ç¥¨ï¼Œæµç¨‹é‡ç½®"))
                else:
                    eligible.sort(key=lambda x: x['rise'], reverse=True)
                    chosen = eligible[len(eligible)//2]

                    # é€²å ´èˆ‡åœæè¨ˆç®—èˆ‡ live ç‰ˆä¸€è‡´
                    rowch   = chosen['row']
                    entry_p = rowch['close']
                    shares  = round((capital_per_stock*10000)/(entry_p*1000))
                    sell_cost = shares * entry_p * 1000
                    entry_fee = int(sell_cost * (transaction_fee*0.01) *
                                    (transaction_discount*0.01))
                    tax   = int(sell_cost * (trading_tax*0.01))
                    if entry_p < 10:
                        gap, tick = price_gap_below_50, 0.01
                    elif entry_p < 50:
                        gap, tick = price_gap_50_to_100, 0.05
                    elif entry_p < 100:
                        gap, tick = price_gap_50_to_100, 0.1
                    elif entry_p < 500:
                        gap, tick = price_gap_100_to_500, 0.5
                    elif entry_p < 1000:
                        gap, tick = price_gap_500_to_1000, 1
                    else:
                        gap, tick = price_gap_above_1000, 5

                    highest_on_entry = rowch['highest'] or entry_p
                    if (highest_on_entry-entry_p)*1000 < gap:
                        stop_thr = entry_p + gap/1000
                    else:
                        stop_thr = highest_on_entry + tick

                    current_position = {
                        'symbol': chosen['symbol'], 'shares': shares,
                        'entry_price': entry_p, 'sell_cost': sell_cost,
                        'entry_fee': entry_fee, 'tax': tax,
                        'entry_time': current_time_str,
                        'current_price_gap': gap, 'tick_unit': tick,
                        'highest_on_entry': highest_on_entry,
                        'stop_loss_threshold': stop_thr
                    }
                    in_position = True
                    has_exited  = False
                    hold_time   = 0
                    pull_up_entry = limit_up_entry = False
                    tracking_stocks.clear()
                    if verbose:
                        message_log.append(
                            (current_time_str,
                             f"{Fore.GREEN}é€²å ´ï¼{chosen['symbol']} {shares}å¼µ "
                             f"åƒ¹ {entry_p:.2f} åœæ {stop_thr:.2f}"
                             f"{Style.RESET_ALL}"))
            else:
                waiting_time += 1
                if verbose:
                    message_log.append(
                        (current_time_str,
                         f"ç­‰å¾…ä¸­ï¼Œç¬¬ {waiting_time} åˆ†é˜"))

    # â•â•â•â•â•â•â•â•â•â•â• 2. å›æ¸¬çµæœè¼¸å‡º â•â•â•â•â•â•â•â•â•â•â• #
    message_log.sort(key=lambda x: x[0])
    for t, msg in message_log:
        print(f"[{t}] {msg}")

    if total_trades:
        avg_rate = total_profit_rate / total_trades
        print(f"\næ¨¡æ“¬å®Œæˆï¼Œç¸½åˆ©æ½¤ï¼š{int(total_profit)} å…ƒï¼Œå¹³å‡å ±é…¬ç‡ï¼š{avg_rate:.2f}%\n")
        return total_profit, avg_rate
    else:
        print("ç„¡äº¤æ˜“ï¼Œç„¡æ³•è¨ˆç®—åˆ©æ½¤")
        return None, None



def pull_up_entry_function(symbol, current_time, current_time_str, row, message_log, tracking_stocks, verbose=True, final_check_active=False, in_waiting_period=False):
    global pull_up_entry, limit_up_entry
    if symbol not in tracking_stocks:
        tracking_stocks.add(symbol)
        if verbose and not in_waiting_period and not final_check_active:
            message_log.append(
                (current_time_str, f"è‚¡ç¥¨ä»£è™Ÿ:{symbol} è§¸ç™¼æ‹‰é«˜é€²å ´æ¢ä»¶")
            )
    first_condition_one_time = current_time
    pull_up_entry = True
    limit_up_entry = False
    return first_condition_one_time

def limit_up_entry_function(symbol, current_time, current_time_str, tracking_stocks, leader, in_waiting_period, waiting_time, message_log, verbose=True):
    global pull_up_entry, limit_up_entry
    tracking_stocks.clear()
    tracking_stocks.add(symbol)
    leader = symbol
    in_waiting_period = True
    waiting_time = 1
    pull_up_entry = False
    limit_up_entry = True
    if verbose:
        message_log.append(
            (current_time_str, f"é ˜æ¼² {symbol} æ¼²åœï¼Œè§¸ç™¼æ¼²åœé€²å ´æ¢ä»¶")
        )
    return leader, in_waiting_period, waiting_time
    
def entry_trade(
    eligible_stocks, current_time, current_time_str, stock_data_collection, idx,
    message_log, already_entered_stocks, tracking_stocks, previous_rise_values, verbose=True
):
    global capital_per_stock, transaction_fee, transaction_discount, trading_tax
    global price_gap_below_50, price_gap_50_to_100, price_gap_100_to_500
    global price_gap_500_to_1000, price_gap_above_1000
    global in_position, has_exited, current_position
    global allow_reentry_after_stop_loss, stop_loss_triggered
    global final_check_active, final_check_count, in_waiting_period, waiting_time
    global hold_time, leader

    if in_position:
        if verbose:
            message_log.append(
                (current_time_str, f"{YELLOW}å·²æœ‰æŒå€‰ï¼Œç„¡æ³•é€²è¡Œæ–°çš„é€²å ´æ“ä½œ{RESET}")
            )
        return

    eligible_stocks_sorted = sorted(eligible_stocks, key=lambda x: x['rise'], reverse=True)
    median_index = len(eligible_stocks_sorted) // 2
    selected_stock = eligible_stocks_sorted[median_index]
    selected_symbol = selected_stock['symbol']
    selected_stock_rise = selected_stock['rise']
    
    entry_price_series = stock_data_collection[selected_symbol][stock_data_collection[selected_symbol]['time'] == current_time]['close']
    if not entry_price_series.empty:
        entry_price = entry_price_series.values[0]
        shares = round((capital_per_stock * 10000) / (entry_price * 1000))
        sell_cost = shares * entry_price * 1000
        entry_fee = int(sell_cost * (transaction_fee * 0.01) * (transaction_discount * 0.01))
        tax = int(sell_cost * (trading_tax * 0.01))
        
        if entry_price < 10:
            current_price_gap = price_gap_below_50
            tick_unit = 0.01
        elif entry_price < 50:
            current_price_gap = price_gap_50_to_100
            tick_unit = 0.05
        elif entry_price < 100:
            current_price_gap = price_gap_50_to_100
            tick_unit = 0.1
        elif entry_price < 500:
            current_price_gap = price_gap_100_to_500
            tick_unit = 0.5
        elif entry_price < 1000:
            current_price_gap = price_gap_500_to_1000
            tick_unit = 1
        else:
            current_price_gap = price_gap_above_1000
            tick_unit = 5

        highest_on_entry_series = stock_data_collection[selected_symbol][stock_data_collection[selected_symbol]['time'] == current_time]['high']
        if not highest_on_entry_series.empty:
            highest_on_entry = highest_on_entry_series.values[0]
        else:
            highest_on_entry = entry_price

        current_position = {
            'symbol': selected_symbol,
            'shares': shares,
            'entry_price': entry_price,
            'sell_cost': sell_cost,
            'entry_fee': entry_fee,
            'tax': tax,
            'entry_time': current_time_str,
            'entry_index': idx,
            'current_price_gap': current_price_gap,
            'tick_unit': tick_unit,
            'highest_on_entry': highest_on_entry,
            'initial_highest': highest_on_entry,
            'stop_loss_type': None,
            'stop_loss_threshold': None
        }
        message_log.append(
            (current_time_str,
             f"{GREEN}é€²å ´ï¼è‚¡ç¥¨ä»£è™Ÿï¼š{selected_symbol}ï¼Œé€²å ´ {shares} å¼µï¼Œé€²å ´åƒ¹æ ¼ï¼š{entry_price} å…ƒï¼Œ"
             f"é€²å ´åƒ¹é‡‘ï¼š{int(sell_cost)} å…ƒï¼Œæ‰‹çºŒè²»ï¼š{entry_fee} å…ƒï¼Œè­‰äº¤ç¨…ï¼š{tax} å…ƒã€‚{RESET}")
        )

        in_position = True
        has_exited = False
        already_entered_stocks.append(selected_symbol)
        hold_time = 0

        if allow_reentry_after_stop_loss:
            stop_loss_triggered = False

        price_difference = (current_position['highest_on_entry'] - current_position['entry_price']) * 1000
        if price_difference < current_position['current_price_gap']:
            current_position['stop_loss_type'] = 'price_difference'
            current_position['stop_loss_threshold'] = current_position['entry_price'] + (current_position['current_price_gap'] / 1000)
        else:
            current_position['stop_loss_type'] = 'over_high'
            current_position['stop_loss_threshold'] = current_position['highest_on_entry'] + current_position['tick_unit']

        final_check_active = False
        final_check_count = 0
        in_waiting_period = False
        waiting_time = 0
        hold_time = 0
        leader = None
        tracking_stocks.clear()
        previous_rise_values.clear()
        leader_peak_rise = None
        leader_rise_before_decline = None
        first_condition_one_time = None
    else:
        message_log.append(
            (current_time_str,
             f"{RED}ç„¡æ³•å–å¾— {selected_symbol} åœ¨ {current_time_str} çš„åƒ¹æ ¼ï¼Œé€²å ´å¤±æ•—{RESET}")
        )

def exit_trade(
    selected_stock_df, shares, entry_price, sell_cost,
    entry_fee, tax,
    message_log, current_time, hold_time, entry_time, use_f_exit=False
):
    global transaction_fee, transaction_discount, trading_tax
    global in_position, has_exited, current_position
    current_time_str = current_time if isinstance(current_time, str) else current_time.strftime('%H:%M:%S')
    selected_stock_df['time'] = pd.to_datetime(selected_stock_df['time'], format='%H:%M:%S').dt.time

    if isinstance(entry_time, str):
        entry_time_obj = datetime.strptime(entry_time, '%H:%M:%S').time()
    else:
        entry_time_obj = entry_time

    if use_f_exit:
        end_time = datetime.strptime('13:30', '%H:%M').time()
        end_price_series = selected_stock_df[selected_stock_df['time'] == end_time]['close']
        if not end_price_series.empty:
            end_price = end_price_series.values[0]
        else:
            print("ç„¡æ³•å–å¾— 13:30 çš„æ•¸æ“šï¼Œå‡ºå ´æ™‚é–“é…å°éŒ¯èª¤")
            message_log.append((current_time_str, f"{RED}å‡ºå ´æ™‚é–“é…å°éŒ¯èª¤{RESET}"))
            return None, None
        entry_datetime = datetime.combine(date.today(), entry_time_obj)
        if isinstance(current_time, datetime):
            current_datetime = current_time
        else:
            current_datetime = datetime.combine(date.today(), current_time)
        hold_time_calculated = int((current_datetime - entry_datetime).total_seconds() / 60)
    else:
        entry_index_series = selected_stock_df[selected_stock_df['time'] == entry_time_obj].index
        if not entry_index_series.empty:
            entry_index = entry_index_series[0]
            exit_index = entry_index + hold_time
            if exit_index >= len(selected_stock_df):
                print("å‡ºå ´æ™‚é–“è¶…å‡ºç¯„åœï¼Œç„¡æ³•é€²è¡Œäº¤æ˜“")
                message_log.append((current_time_str, f"{RED}å‡ºå ´æ™‚é–“è¶…å‡ºç¯„åœ{RESET}"))
                return None, None
            end_price = selected_stock_df.iloc[exit_index]['close']
        else:
            print("é€²å ´æ™‚é–“é…å°éŒ¯èª¤ï¼Œç„¡æ³•æ‰¾åˆ°ç²¾ç¢ºçš„é€²å ´æ™‚é–“")
            message_log.append((current_time_str, f"{RED}é€²å ´æ™‚é–“é…å°éŒ¯èª¤{RESET}"))
            return None, None
        hold_time_calculated = hold_time

    buy_cost = shares * end_price * 1000
    exit_fee = int(buy_cost * (transaction_fee * 0.01) * (transaction_discount * 0.01))
    profit = sell_cost - buy_cost - entry_fee - exit_fee - tax
    return_rate = (profit * 100) / (buy_cost - exit_fee) if (buy_cost - exit_fee) != 0 else 0.0

    if use_f_exit:
        message_log.append(
            (current_time_str,
             f"{RED}è‚¡ç¥¨å‡ºå ´ï¼ŒæŒæœ‰æ™‚é–“ {hold_time_calculated} åˆ†é˜ï¼ˆå¼·åˆ¶å‡ºå ´ï¼‰{RESET}")
        )
    else:
        message_log.append(
            (current_time_str,
             f"{RED}è‚¡ç¥¨å‡ºå ´ï¼ŒæŒæœ‰æ™‚é–“ {hold_time_calculated} åˆ†é˜{RESET}")
        )
    message_log.append(
        (current_time_str,
         f"{RED}æŒæœ‰å¼µæ•¸ï¼š{shares} å¼µï¼Œå‡ºå ´åƒ¹æ ¼ï¼š{end_price} å…ƒï¼Œå‡ºå ´åƒ¹é‡‘ï¼š{int(buy_cost)} å…ƒï¼Œåˆ©æ½¤ï¼š{int(profit)} å…ƒï¼Œ"
         f"å ±é…¬ç‡ï¼š{return_rate:.2f}%ï¼Œæ‰‹çºŒè²»ï¼š{exit_fee} å…ƒ{RESET}")
    )

    in_position = False
    has_exited = True
    return profit, return_rate

def consolidate_and_save_stock_symbols():
    mt_matrix_dict = load_mt_matrix_dict()
    matrix_dict_analysis = load_matrix_dict_analysis()
    
    if not mt_matrix_dict:
        print("mt_matrix_dict.json æ–‡ä»¶ä¸å­˜åœ¨æˆ–ç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œçµ±æ•´")
        return
    if not matrix_dict_analysis:
        print("matrix_dict_analysis.json æ–‡ä»¶ä¸å­˜åœ¨æˆ–ç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œçµ±æ•´")
        return
    consolidated_group_symbols = {group: [] for group in matrix_dict_analysis.keys()}
    
    for group, records in mt_matrix_dict.items():
        for record in records:
            if isinstance(record, dict):
                stock1 = record.get('stock1')
                stock2 = record.get('stock2')
                similarity_score = record.get('similarity_score', 0)
                
                if similarity_score >= 0.3:
                    for analysis_group, symbols in matrix_dict_analysis.items():
                        if stock1 in symbols and stock1 not in consolidated_group_symbols[analysis_group]:
                            consolidated_group_symbols[analysis_group].append(stock1)
                        if stock2 in symbols and stock2 not in consolidated_group_symbols[analysis_group]:
                            consolidated_group_symbols[analysis_group].append(stock2)
            else:
                print(f"è­¦å‘Šï¼šé æœŸå­—å…¸ä½†ç²å¾— {type(record)}ï¼Œè·³éè©²è¨˜éŒ„ã€‚")
    
    for group in consolidated_group_symbols:
        consolidated_group_symbols[group] = list(set(consolidated_group_symbols[group]))
    nb_matrix_dict = {"consolidated_symbols": consolidated_group_symbols}
    save_nb_matrix_dict(nb_matrix_dict)
    print(f"çµ±æ•´å¾Œçš„è‚¡ç¥¨ä»£è™Ÿå·²ä¿å­˜è‡³ nb_matrix_dict.jsonï¼ŒæŒ‰æ—ç¾¤åˆ†é¡ã€‚")

def calculate_kline_similarity(stock_data_list):
    similarity_results = []
    num_stocks = len(stock_data_list)
    for i in range(num_stocks):
        stock1 = stock_data_list[i]
        if 'symbol' not in stock1.columns:
            raise KeyError("DataFrame does not contain 'symbol' column.")
        symbol1 = stock1['symbol'].iloc[0]
        for j in range(i + 1, num_stocks):
            stock2 = stock_data_list[j]
            if 'symbol' not in stock2.columns:
                raise KeyError("DataFrame does not contain 'symbol' column.")
            symbol2 = stock2['symbol'].iloc[0]
            if symbol1 != symbol2:
                merged_df = pd.merge(stock1, stock2, on='time', suffixes=('_1', '_2'))
                merged_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹_2'] = merged_df['æ˜¨æ—¥æ”¶ç›¤åƒ¹_2'].ffill().bfill()
                if 'high_1' not in merged_df.columns or 'high_2' not in merged_df.columns:
                    print(f"è‚¡ç¥¨ {symbol1} æˆ– {symbol2} ç¼ºå°‘ 'high' æ¬„ä½ï¼Œè·³éç›¸ä¼¼åº¦è¨ˆç®—ã€‚")
                    continue
                for col in ['open', 'high', 'low', 'close']:
                    merged_df[f'{col}_1_z'] = (merged_df[f'{col}_1'] - merged_df[f'{col}_1'].mean()) / merged_df[f'{col}_1'].std()
                    merged_df[f'{col}_2_z'] = (merged_df[f'{col}_2'] - merged_df[f'{col}_2'].mean()) / merged_df[f'{col}_2'].std()
                distance = np.sqrt(
                    (merged_df['open_1_z'] - merged_df['open_2_z']) ** 2 +
                    (merged_df['high_1_z'] - merged_df['high_2_z']) ** 2 +
                    (merged_df['low_1_z'] - merged_df['low_2_z']) ** 2 +
                    (merged_df['close_1_z'] - merged_df['close_2_z']) ** 2
                ).mean()
                similarity_score = 1 / (1 + distance)
                if similarity_score >= 0.3:
                    result = {
                        'stock1': symbol1,
                        'stock2': symbol2,
                        'similarity_score': similarity_score
                    }
                    similarity_results.append(result)
    if not similarity_results:
        print("æ²’æœ‰æ‰¾åˆ°ç›¸ä¼¼åº¦å¤§æ–¼ç­‰æ–¼ 0.3 çš„çµæœ")
        return pd.DataFrame(columns=['stock1', 'stock2', 'similarity_score'])
    similarity_df = pd.DataFrame(similarity_results)
    similarity_df = similarity_df.sort_values(by='similarity_score', ascending=False).reset_index(drop=True)
    return similarity_df

def calculate_limit_up_price(close_price):
    limit_up = close_price * 1.10
    if limit_up < 10:
        price_unit = 0.01
    elif limit_up < 50:
        price_unit = 0.05
    elif limit_up < 100:
        price_unit = 0.1
    elif limit_up < 500:
        price_unit = 0.5
    elif limit_up < 1000:
        price_unit = 1
    else:
        price_unit = 5
    limit_up_price = (limit_up // price_unit) * price_unit
    return limit_up_price

def save_mt_matrix_dict(mt_matrix_dict):
    with open('mt_matrix_dict.json', 'w', encoding='utf-8') as f:
        json.dump(mt_matrix_dict, f, indent=4, ensure_ascii=False, default=str)

def load_mt_matrix_dict():
    if os.path.exists('mt_matrix_dict.json'):
        with open('mt_matrix_dict.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        return {}

def load_nb_matrix_dict():
    if os.path.exists('nb_matrix_dict.json'):
        with open('nb_matrix_dict.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    else:
        return {}
    
def ensure_continuous_time_series(df):
    df['date'] = pd.to_datetime(df['date'])
    df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.time

    full_time_index = pd.date_range(start='09:00', end='13:30', freq='1min').time
    full_index = pd.MultiIndex.from_product([df['date'].unique(), full_time_index], names=['date', 'time'])

    df.set_index(['date', 'time'], inplace=True)
    df = df.reindex(full_index)
    df[['symbol', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹']] = df[['symbol', 'æ˜¨æ—¥æ”¶ç›¤åƒ¹', 'æ¼²åœåƒ¹']].ffill().bfill()

    if 'high' not in df.columns:
        df['high'] = df['close']
    if 'low' not in df.columns:
        df['low'] = df['close']

    df['close'] = df['close'].ffill()
    df['close'] = df['close'].fillna(df['æ˜¨æ—¥æ”¶ç›¤åƒ¹'])
    df['open'] = df['open'].ffill()
    df['open'] = df['open'].fillna(df['close'])
    df['high'] = df['high'].ffill()
    df['high'] = df['high'].fillna(df['close'])
    df['low'] = df['low'].ffill()
    df['low'] = df['low'].fillna(df['close'])
    df['volume'] = df['volume'].fillna(0)

    if '5min_pct_increase' not in df.columns:
        df['5min_pct_increase'] = 0.0
    else:
        df['5min_pct_increase'] = df['5min_pct_increase'].fillna(0.0)

    df.reset_index(inplace=True)
    return df
        
def load_disposition_stocks():
    disposition_file = 'Disposition.json'
    try:
        with open(disposition_file, 'r', encoding='utf-8') as f:
            disposition_data = json.load(f)
            return disposition_data
    except FileNotFoundError:
        print(f"éŒ¯èª¤ï¼šç„¡æ³•æ‰¾åˆ° {disposition_file} æ–‡ä»¶ã€‚")
        return []
    except json.JSONDecodeError:
        print(f"éŒ¯èª¤ï¼š{disposition_file} æ–‡ä»¶æ ¼å¼ä¸æ­£ç¢ºã€‚")
        return []
    
def fetch_disposition_stocks(client, matrix_dict_analysis):
    disposition_stocks = []
    for group, stock_list in matrix_dict_analysis.items():
        for symbol in stock_list:
            try:
                ticker_data = client.stock.intraday.ticker(symbol=symbol)
                if ticker_data.get('isDisposition', False):
                    disposition_stocks.append(symbol)
            except Exception as e:
                print(f"ç²å– {symbol} çš„è™•ç½®è‚¡ç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    with open('Disposition.json', 'w', encoding='utf-8') as f:
        json.dump(disposition_stocks, f, indent=4, ensure_ascii=False)

def calculate_average_over_high_list():
    while True:
        print('\n' + '=' * 50)
        print("é¸æ“‡è¨ˆç®—å¹³å‡éé«˜çš„æ¨¡å¼ï¼š")
        print("1. å–®ä¸€æ—ç¾¤åˆ†æ")
        print("2. å…¨éƒ¨æ—ç¾¤åˆ†æ")
        print("0. è¿”å›ä¸»é¸å–®")
        
        sub_choice = input("è«‹è¼¸å…¥é¸é …ï¼š")
        if sub_choice == '1':
            calculate_average_over_high()
        elif sub_choice == '2':
            matrix_dict_analysis = load_matrix_dict_analysis()
            all_group_names = list(matrix_dict_analysis.keys())
            if not all_group_names:
                print("æ²’æœ‰ä»»ä½•æ—ç¾¤è³‡æ–™å¯ä¾›åˆ†æã€‚")
                continue
            print("é–‹å§‹åˆ†ææ‰€æœ‰æ—ç¾¤ä¸­çš„è‚¡ç¥¨...")
            all_group_over_high_averages = []

            for i, group in enumerate(all_group_names):
                print(f"\n=== åˆ†ææ—ç¾¤ï¼š{group} ===")
                group_average = calculate_average_over_high(group_name=group)
                if group_average is not None:
                    all_group_over_high_averages.append(group_average)
                    
            if all_group_over_high_averages:
                overall_group_average = sum(all_group_over_high_averages) / len(all_group_over_high_averages)
                print(f"\nå…¨éƒ¨æ—ç¾¤çš„å¹³å‡éé«˜é–“éš”ï¼š{overall_group_average:.2f} åˆ†é˜")
            else:
                print("\næ²’æœ‰ä»»ä½•æ—ç¾¤ç™¼ç”Ÿéé«˜é–“éš”çš„æƒ…å½¢ã€‚")
        elif sub_choice == '0':
            main_menu()
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

def load_kline_data():
    daily_kline_data = {}
    intraday_kline_data = {}

    if os.path.exists('daily_kline_data.json'):
        with open('daily_kline_data.json', 'r', encoding='utf-8') as f:
            try:
                daily_kline_data = json.load(f)
                if not daily_kline_data:
                    print("æ—¥Kç·šæ•¸æ“šæª”æ¡ˆç‚ºç©ºï¼Œè«‹å…ˆæ›´æ–°æ•¸æ“šã€‚")
            except json.JSONDecodeError:
                print("æ—¥Kç·šæ•¸æ“šæª”æ¡ˆæ ¼å¼éŒ¯èª¤ï¼Œè«‹å…ˆæ›´æ–°æ•¸æ“šã€‚")

    if os.path.exists('intraday_kline_data.json'):
        with open('intraday_kline_data.json', 'r', encoding='utf-8') as f:
            try:
                intraday_kline_data = json.load(f)
                if not intraday_kline_data:
                    print("ä¸€åˆ†Kç·šæ•¸æ“šæª”æ¡ˆç‚ºç©ºï¼Œè«‹å…ˆæ›´æ–°æ•¸æ“šã€‚")
            except json.JSONDecodeError:
                print("ä¸€åˆ†Kç·šæ•¸æ“šæª”æ¡ˆæ ¼å¼éŒ¯èª¤ï¼Œè«‹å…ˆæ›´æ–°æ•¸æ“šã€‚")

    return daily_kline_data, intraday_kline_data

def calculate_average_over_high(group_name=None):
    daily_kline_data, intraday_kline_data = load_kline_data()

    matrix_dict_analysis = load_matrix_dict_analysis()
    
    if group_name is None:
        group_name = input("è«‹è¼¸å…¥è¦åˆ†æçš„æ—ç¾¤åç¨±ï¼š")
    
    if group_name not in matrix_dict_analysis:
        print("æ²’æœ‰æ­¤æ—ç¾¤è³‡æ–™")
        return None

    symbols_to_analyze = matrix_dict_analysis[group_name]
    disposition_stocks = load_disposition_stocks()
    symbols_to_analyze = [symbol for symbol in symbols_to_analyze if symbol not in disposition_stocks]

    if not symbols_to_analyze:
        print(f"{group_name} ä¸­æ²’æœ‰å¯ä¾›åˆ†æçš„è‚¡ç¥¨ã€‚")
        return None

    print(f"é–‹å§‹åˆ†ææ—ç¾¤ {group_name} ä¸­çš„è‚¡ç¥¨...")
    any_condition_one_triggered = False 
    group_over_high_averages = []

    for symbol in symbols_to_analyze:
        print(f"\næ­£åœ¨åˆ†æè‚¡ç¥¨ï¼š{symbol}")
        
        if symbol not in daily_kline_data or symbol not in intraday_kline_data:
            print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥ K ç·šæˆ–ä¸€åˆ† K ç·šæ•¸æ“šï¼Œè·³éã€‚")
            continue
        
        daily_kline_df = pd.DataFrame(daily_kline_data[symbol])
        intraday_data = pd.DataFrame(intraday_kline_data[symbol])

        condition_one_triggered = False
        condition_two_triggered = False
        previous_high = None
        condition_two_time = None
        over_high_intervals = []

        for idx, row in intraday_data.iterrows():
            current_time = pd.to_datetime(row['time']).time()
            if previous_high is None:
                previous_high = row['high']
                continue

            if not condition_one_triggered:
                if row['5min_pct_increase'] >= 2:
                    condition_one_triggered = True
                    condition_two_triggered = False
                    any_condition_one_triggered = True

                    print(f"{symbol} è§¸ç™¼æ¢ä»¶ä¸€ï¼Œé–‹å§‹ç›£æ¸¬äº”åˆ†é˜æ¼²å¹…ï¼Œäº”åˆ†é˜æ¼²å¹…: {row['5min_pct_increase']:.2f}%")

            if condition_one_triggered and not condition_two_triggered:
                if row['high'] <= previous_high:
                    current_time_str = current_time.strftime('%H:%M:%S')
                    print(f"{symbol} è§¸ç™¼æ¢ä»¶äºŒï¼æ™‚é–“ï¼š{current_time_str}")

                    condition_two_time = current_time
                    condition_two_triggered = True

            elif condition_two_triggered:
                if row['highest'] > previous_high:
                    condition_three_time_str = current_time.strftime('%H:%M:%S')
                    print(f"{symbol} è§¸ç™¼æ¢ä»¶ä¸‰ï¼æ™‚é–“ï¼š{condition_three_time_str}")
                    if condition_two_time:
                        today = datetime.today().date()
                        condition_two_datetime = datetime.combine(today, condition_two_time)
                        condition_three_datetime = datetime.combine(today, current_time)
                        interval = (condition_three_datetime - condition_two_datetime).total_seconds() / 60
                        print(f"{symbol} éé«˜é–“éš”ï¼š{interval:.2f} åˆ†é˜")
                        over_high_intervals.append(interval)

                    condition_one_triggered = False
                    condition_two_triggered = False
                    condition_two_time = None

            previous_high = row['high']

        if over_high_intervals:
            q1 = np.percentile(over_high_intervals, 25)
            q3 = np.percentile(over_high_intervals, 75)
            iqr = q3 - q1
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            filtered_intervals = [interval for interval in over_high_intervals if lower_bound <= interval <= upper_bound]
            if filtered_intervals:
                average_interval = sum(filtered_intervals) / len(filtered_intervals)
                print(f"{symbol} å¹³å‡éé«˜é–“éš”ï¼š{average_interval:.2f} åˆ†é˜")
                group_over_high_averages.append(average_interval)
            else:
                print(f"{symbol} æ²’æœ‰æœ‰æ•ˆçš„éé«˜é–“éš”æ•¸æ“š")
        else:
            print(f"{symbol} æ²’æœ‰è§¸ç™¼éé«˜é–“éš”çš„æƒ…å½¢")

    if group_over_high_averages:
        group_average_over_high = sum(group_over_high_averages) / len(group_over_high_averages)
        print(f"{group_name} å¹³å‡éé«˜é–“éš”ï¼š{group_average_over_high:.2f} åˆ†é˜")
        return group_average_over_high
    else:
        print(f"{group_name} æ²’æœ‰æœ‰æ•ˆçš„éé«˜é–“éš”æ•¸æ“š")
        return None

def main_menu():
    global capital_per_stock
    load_settings()
    print('\n' + '=' * 50)
    print(f"\nç›®å‰è‚¡ç¥¨çš„å–®ç­†æŠ•å…¥è³‡æœ¬é¡ç‚º{capital_per_stock}è¬å…ƒ")
    while True:
        print("è«‹é¸æ“‡åŠŸèƒ½ï¼š")
        print("1. å›æ¸¬ç¨‹å¼")
        print("2. ä¸‹å–®ç¨‹å¼")
        print("3. ç®¡ç†æ—ç¾¤")
        print("4. è¨­å®šé¸å–®")
        print("5. æ›´æ–°Kç·šæ•¸æ“š")
        print("6. æŸ¥è©¢è™•ç½®è‚¡")
        print("0. é€€å‡ºç¨‹å¼")
        print('\n' + '=' * 50)
        choice = input("è«‹è¼¸å…¥é¸é …ï¼š")
        if choice == '1':
            backtesting_menu_list()
        elif choice == '2':
            trading_menu_list()
        elif choice == '3':
            manage_groups()
        elif choice == '4':
            settings_menu()
        elif choice == '5':
            update_kline_data_menu()
        elif choice == '6':
            display_disposition_stocks()
        elif choice == '0':
            print("é€€å‡ºç¨‹å¼...å†è¦‹")
            break
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

def backtesting_menu_list():
    print('\n' + '=' * 50)
    print("\nè«‹é¸æ“‡åŠŸèƒ½ï¼š")
    print("1. è¨ˆç®—å¹³å‡éé«˜ã€2. è‡ªé¸é€²å ´æ¨¡å¼ã€3. æ¥µå¤§åŒ–åˆ©æ½¤æ¨¡å¼ã€0. è¿”å›ä¸»é¸å–®")
    print('\n' + '=' * 50)
    back_choice = input("è«‹é¸æ“‡åŠŸèƒ½ï¼š")
    if back_choice == '1':
        calculate_average_over_high_list()
    elif back_choice == '2':
        simulate_trading_menu()
    elif back_choice == '3':
        maximize_profit_analysis()
    elif back_choice == '0':
        main_menu()
    else:
        print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

def trading_menu_list():
    print('\n' + '=' * 50)
    print("\nè«‹é¸æ“‡åŠŸèƒ½ï¼š")
    print("1. é–‹å§‹äº¤æ˜“ã€2. ç™»å…¥å¸³æˆ¶ã€3. ä¿®æ”¹apié‡‘é‘°ã€0. è¿”å›ä¸»é¸å–®")
    print('\n' + '=' * 50)
    back_choice = input("è«‹é¸æ“‡åŠŸèƒ½ï¼š")
    if back_choice == '1':
        start_trading()
    elif back_choice == '2':
        login()
    elif back_choice == '0':
        main_menu()
    else:
        print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

capital_per_stock = 0
transaction_fee = 0
transaction_discount = 0
trading_tax = 0
below_50 = 0
price_gap_50_to_100 = 0
price_gap_100_to_500 = 0
price_gap_500_to_1000 = 0
price_gap_above_1000 = 0
allow_reentry_after_stop_loss = False

def load_symbols_to_analyze():
    nb_matrix_dict = load_nb_matrix_dict()
    consolidated_symbols = nb_matrix_dict.get("consolidated_symbols", {})
    symbols = []
    for group_symbols in consolidated_symbols.values():
        symbols.extend(group_symbols)
    disposition_stocks = load_disposition_stocks()
    symbols = [symbol for symbol in symbols if symbol not in disposition_stocks]
    return symbols

def load_group_symbols():
    if not os.path.exists('nb_matrix_dict.json'):
        print("nb_matrix_dict.json æ–‡ä»¶ä¸å­˜åœ¨ã€‚")
        return {}
    with open('nb_matrix_dict.json', 'r', encoding='utf-8') as f:
        group_symbols = json.load(f)
    return group_symbols

# æŠŠè™•ç½®è‚¡å¾ nb_matrix_dict.json å‰”é™¤
def purge_disposition_from_nb(disposition_list, nb_path='nb_matrix_dict.json'):
    """
    disposition_list : List[str]  # è™•ç½®è‚¡ä»£è™Ÿæ¸…å–®
    nb_path          : str        # nb_matrix_dict æª”æ¡ˆè·¯å¾‘
    --------------
    è®€å– nb_matrix_dict.json â†’ consolidated_symbols
    è‹¥è©²è‚¡ç¥¨ä»£è™Ÿå‡ºç¾åœ¨ disposition_listï¼Œä¾¿å°‡å…¶å¾å°æ‡‰æ—ç¾¤ç§»é™¤ã€‚
    æœ‰ç•°å‹•æ‰è¦†å¯«æª”æ¡ˆã€‚
    """
    if not os.path.exists(nb_path):
        print(f"æ‰¾ä¸åˆ° {nb_path}ï¼Œè·³éè™•ç½®è‚¡éæ¿¾ã€‚")
        return

    try:
        with open(nb_path, 'r', encoding='utf-8') as f:
            nb_dict = json.load(f)
    except json.JSONDecodeError:
        print(f"{nb_path} æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è§£æï¼Œè·³ééæ¿¾ã€‚")
        return

    if 'consolidated_symbols' not in nb_dict or not isinstance(nb_dict['consolidated_symbols'], dict):
        print(f"{nb_path} ç¼ºå°‘ consolidated_symbolsï¼Œè·³ééæ¿¾ã€‚")
        return

    changed = False
    for grp, syms in nb_dict['consolidated_symbols'].items():
        # åŸæœ¬å¯èƒ½æœ‰é‡è¤‡ï¼Œå…ˆå»é‡å†éæ¿¾
        filtered = [s for s in dict.fromkeys(syms) if s not in disposition_list]
        if len(filtered) != len(syms):
            nb_dict['consolidated_symbols'][grp] = filtered
            changed = True

    # è‹¥æœ‰ç•°å‹•ï¼Œå¯«å›æª”æ¡ˆ
    if changed:
        with open(nb_path, 'w', encoding='utf-8') as f:
            json.dump(nb_dict, f, ensure_ascii=False, indent=4)
        print(f"å·²å¾ {nb_path} ç§»é™¤è™•ç½®è‚¡ï¼š{', '.join(disposition_list)}")
    else:
        print("nb_matrix_dict.json ç„¡éœ€èª¿æ•´ï¼ŒæœªåŒ…å«ä»»ä½•è™•ç½®è‚¡ã€‚")

# æª¢æŸ¥ç›¤ä¸­é€€å‡º
def check_quit_flag_loop():
    while True:
        time_module.sleep(5)  # æ¯ 5 ç§’æª¢æŸ¥ä¸€æ¬¡
        if quit_flag["quit"]:
            threading.Thread(target=show_exit_menu, daemon=True).start()
            quit_flag["quit"] = False

def start_trading(mode='full', wait_minutes=None, hold_minutes=None):
    """
    mode:
        'full' â€“ ç¬¬ä¸€æ¬¡åŸ·è¡Œï¼šæ­£å¸¸è©¢å•ç­‰å¾…/æŒæœ‰åˆ†é˜ã€‚
        'post' â€“ ç›¤å¾Œéè¿´å‘¼å«ï¼šæ²¿ç”¨ä¸Šä¸€è¼ª wait_minutes / hold_minutesï¼Œä¸å†è©¢å•ã€‚
    """
    client, api_key = init_fugle_client()

    # ===== è™•ç½®è‚¡éæ¿¾=====
    matrix_dict_analysis = load_matrix_dict_analysis()
    fetch_disposition_stocks(client, matrix_dict_analysis)   # â‘  å…ˆæ›´æ–° Disposition.json
    disposition_stocks = load_disposition_stocks()           # â‘¡ è®€æœ€æ–°è™•ç½®è‚¡
    purge_disposition_from_nb(disposition_stocks)           # â‘¢ åˆª nb_matrix_dict ä¸­çš„è™•ç½®è‚¡
    # ====================

    symbols_to_analyze = load_symbols_to_analyze()
    stop_trading = False
    max_symbols_to_fetch = 20

    group_symbols = load_group_symbols()
    if not group_symbols:
        print("æ²’æœ‰åŠ è¼‰åˆ°ä»»ä½•æ—ç¾¤è³‡æ–™ï¼Œè«‹ç¢ºèª nb_matrix_dict.json çš„å­˜åœ¨èˆ‡å…§å®¹ã€‚")
        return
    consolidated_symbols = group_symbols.get('consolidated_symbols', {})
    if not consolidated_symbols:
        print("æ²’æœ‰æ‰¾åˆ° 'consolidated_symbols'ï¼Œè«‹ç¢ºèªè³‡æ–™çµæ§‹ã€‚")
        return
    group_positions = {group: False for group in consolidated_symbols.keys()}

    # æ™‚é–“åˆ¤æ–·
    now = datetime.now()
    now_str = now.strftime('%Y-%m-%d %H:%M:%S')
    pre_market_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    market_start     = now.replace(hour=9, minute=0, second=0, microsecond=0)
    market_end       = now.replace(hour=13, minute=30, second=0, microsecond=0)
    post_switch      = now.replace(hour=13, minute=31, second=0, microsecond=0)

    # å…ˆåˆ†æ”¯ï¼šç›¤å‰ã€ç›¤ä¸­ã€è½‰ç›¤å¾Œéæ¸¡ã€ç›¤å¾Œ
    if pre_market_start <= now < market_start:
        print(f"ç›®å‰ç‚º {now_str}ï¼Œç›¤å‰æ™‚é–“ï¼Œåªæ›´æ–°æ—¥Kç·šè³‡æ–™ã€‚")
        # ---------- å–å¾— / æ¯”å°æ—¥ Kï¼ˆç›¤å‰ï¼‰ ----------
        existing_auto_daily_data = {}
        if os.path.exists('auto_daily.json'):
            with open('auto_daily.json', 'r', encoding='utf-8') as f:
                try:
                    existing_auto_daily_data = json.load(f)
                except json.JSONDecodeError:
                    existing_auto_daily_data = {}
        else:
            print("auto_daily.json ä¸å­˜åœ¨ï¼Œå°‡å»ºç«‹æ–°çš„ã€‚")

        print("é–‹å§‹å–å¾—æ—¥Kç·šæ•¸æ“šä¸¦èˆ‡ç¾æœ‰è³‡æ–™æ¯”å°...")
        auto_daily_data = {}
        data_is_same = True
        initial_api_count = 0
        symbols_fetched = 0

        for symbol in symbols_to_analyze[:max_symbols_to_fetch]:
            if initial_api_count >= 55:
                print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
                time_module.sleep(60)
                initial_api_count = 0
            daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
            initial_api_count += 1
            if daily_kline_df.empty:
                print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
                continue
            daily_kline_data = daily_kline_df.to_dict(orient='records')
            auto_daily_data[symbol] = daily_kline_data
            existing_data = existing_auto_daily_data.get(symbol)
            if existing_data != daily_kline_data:
                data_is_same = False
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
                existing_auto_daily_data[symbol] = daily_kline_data
            else:
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")
            symbols_fetched += 1

        if not data_is_same:
            remaining_symbols = symbols_to_analyze[max_symbols_to_fetch:]
            print(f"ç™¼ç¾å‰ {max_symbols_to_fetch} æ”¯è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šæœ‰æ›´æ–°ï¼Œé–‹å§‹å–å¾—å‰©é¤˜è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šä¸¦æ›´æ–°ã€‚")
            for symbol in remaining_symbols:
                if initial_api_count >= 55:
                    print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
                    time_module.sleep(60)
                    initial_api_count = 0
                daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
                initial_api_count += 1
                if daily_kline_df.empty:
                    print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
                    continue
                daily_kline_data = daily_kline_df.to_dict(orient='records')
                auto_daily_data[symbol] = daily_kline_data
                existing_data = existing_auto_daily_data.get(symbol)
                if existing_data != daily_kline_data:
                    print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
                    existing_auto_daily_data[symbol] = daily_kline_data
                else:
                    print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")

        if symbols_fetched < max_symbols_to_fetch:
            print(f"æ³¨æ„ï¼šåƒ…å–å¾—äº† {symbols_fetched} æ”¯è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šã€‚")

        with open('auto_daily.json', 'w', encoding='utf-8') as f:
            json.dump(existing_auto_daily_data, f, ensure_ascii=False, indent=4)
        print("{YELLOW}å·²æ›´æ–° auto_daily.jsonã€‚{RESET}")

        print("{YELLOW}ç›¤å‰æ›´æ–°å®Œæˆï¼Œè¿”å›ä¸»é¸å–®ã€‚{RESET}")
        return

    elif market_start <= now <= market_end:
        print(f"ç›®å‰ç‚º {now_str}ï¼Œç›¤ä¸­äº¤æ˜“æ™‚é–“ã€‚")
        # ---------- 1. ç¬¬ä¸€æ¬¡åŸ·è¡Œè©¢å•ä½¿ç”¨è€… ----------
        if mode == 'full':
            try:
                wait_minutes = int(input("è«‹è¼¸å…¥ç­‰å¾…æ™‚é–“ï¼ˆåˆ†é˜ï¼‰ï¼š"))
            except ValueError:
                print("ç­‰å¾…æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸ã€‚")
                return
            hold_minutes_input = input("è«‹è¼¸å…¥æŒæœ‰æ™‚é–“ï¼ˆåˆ†é˜ï¼Œè¼¸å…¥ 'F' ä»£è¡¨æŒæœ‰åˆ°13:30å¼·åˆ¶å‡ºå ´ï¼‰ï¼š")
            if hold_minutes_input.upper() == 'F':
                hold_minutes = None
            else:
                try:
                    hold_minutes = int(hold_minutes_input)
                except ValueError:
                    print("æŒæœ‰æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸æˆ– 'F'ã€‚")
                    return
        else:
            assert wait_minutes is not None

        # ---------- 2. å–å¾— / æ¯”å°æ—¥ Kï¼ˆç›¤ä¸­ä¹Ÿéœ€è¦æ—¥Kï¼‰ ----------
        existing_auto_daily_data = {}
        if os.path.exists('auto_daily.json'):
            with open('auto_daily.json', 'r', encoding='utf-8') as f:
                try:
                    existing_auto_daily_data = json.load(f)
                except json.JSONDecodeError:
                    existing_auto_daily_data = {}
        print("é–‹å§‹å–å¾—æ—¥Kç·šæ•¸æ“šä¸¦èˆ‡ç¾æœ‰è³‡æ–™æ¯”å°...")
        auto_daily_data = {}
        data_is_same = True
        initial_api_count = 0
        symbols_fetched = 0
        for symbol in symbols_to_analyze[:max_symbols_to_fetch]:
            if initial_api_count >= 55:
                print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
                time_module.sleep(60)
                initial_api_count = 0
            daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
            initial_api_count += 1
            if daily_kline_df.empty:
                print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
                continue
            daily_kline_data = daily_kline_df.to_dict(orient='records')
            auto_daily_data[symbol] = daily_kline_data
            existing_data = existing_auto_daily_data.get(symbol)
            if existing_data != daily_kline_data:
                data_is_same = False
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
                existing_auto_daily_data[symbol] = daily_kline_data
            else:
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")
            symbols_fetched += 1
        if not data_is_same:
            remaining_symbols = symbols_to_analyze[max_symbols_to_fetch:]
            print(f"ç™¼ç¾å‰ {max_symbols_to_fetch} æ”¯è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šæœ‰æ›´æ–°ï¼Œé–‹å§‹å–å¾—å‰©é¤˜è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šä¸¦æ›´æ–°ã€‚")
            for symbol in remaining_symbols:
                if initial_api_count >= 55:
                    print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
                    time_module.sleep(60)
                    initial_api_count = 0
                daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
                initial_api_count += 1
                if daily_kline_df.empty:
                    print(f"ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
                    continue
                daily_kline_data = daily_kline_df.to_dict(orient='records')
                auto_daily_data[symbol] = daily_kline_data
                existing_data = existing_auto_daily_data.get(symbol)
                if existing_data != daily_kline_data:
                    print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
                    existing_auto_daily_data[symbol] = daily_kline_data
                else:
                    print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")
        if symbols_fetched < max_symbols_to_fetch:
            print(f"æ³¨æ„ï¼šåƒ…å–å¾—äº† {symbols_fetched} æ”¯è‚¡ç¥¨çš„æ—¥Kæ•¸æ“šã€‚")
        with open('auto_daily.json', 'w', encoding='utf-8') as f:
            json.dump(existing_auto_daily_data, f, ensure_ascii=False, indent=4)
        print("å·²æ›´æ–° auto_daily.jsonã€‚")

        # ---------- 3. è£œé½Šä¸€åˆ†Kï¼ˆç›¤ä¸­æ¯æ¬¡éƒ½è¦å°ç•¶æ—¥åšåˆæ¬¡è£œé½Šï¼‰ ----------
        fetch_time = datetime.now() - timedelta(minutes=1)
        trading_day = fetch_time.strftime('%Y-%m-%d')
        '''
        print(f"æ—¥æœŸæ¨£æœ¬ï¼š{trading_day}")
        '''
        
        yesterday_close_prices = {}
        # ï¼ˆæ­¤è™•ä¿æŒã€Œè®€æ˜¨æ”¶ã€é‚è¼¯ä¸è®Šï¼‰
        for symbol in symbols_to_analyze:
            daily_data = existing_auto_daily_data.get(symbol, [])
            if not daily_data:
                daily_kline_df = fetch_daily_kline_data(client, symbol, days=5)
                if not daily_kline_df.empty:
                    daily_kline_data = daily_kline_df.to_dict(orient='records')
                    existing_auto_daily_data[symbol] = daily_kline_data
                    with open('auto_daily.json', 'w', encoding='utf-8') as f:
                        json.dump(existing_auto_daily_data, f, ensure_ascii=False, indent=4)
                if len(existing_auto_daily_data[symbol]) > 1:
                    now2 = datetime.now()
                    weekday = now2.weekday()
                    if 0 <= weekday <= 4 and 8 <= now2.hour < 15:
                        yesterday_close = existing_auto_daily_data[symbol][0].get('close', 0)
                    else:
                        yesterday_close = existing_auto_daily_data[symbol][1].get('close', 0)
                else:
                    yesterday_close = 0
                yesterday_close_prices[symbol] = yesterday_close
            else:
                sorted_daily_data = sorted(daily_data, key=lambda x: x['date'], reverse=True)
                if len(sorted_daily_data) > 1:
                    now2 = datetime.now()
                    weekday = now2.weekday()
                    if 0 <= weekday <= 4 and 8 <= now2.hour < 15:
                        yesterday_close = sorted_daily_data[0].get('close', 0)
                    else:
                        yesterday_close = sorted_daily_data[1].get('close', 0)
                else:
                    yesterday_close = sorted_daily_data[0].get('close', 0)
                yesterday_close_prices[symbol] = yesterday_close

        # ä¸€åˆ†Kåˆæ¬¡è£œé½Š

        # æ¸¬è©¦è¨Šæ¯
        t_fetch_hist = time_module.perf_counter()
        print("ğŸ” [æ­·å²] é–‹å§‹è£œé½Šä¸€åˆ†Kè³‡æ–™...")
        
        market_real_end       = now.replace(hour=13, minute=30, second=0, microsecond=0)

        if now < market_real_end :
            full_intraday_end = (now - timedelta(minutes=1)).strftime('%H:%M')
        else:
            full_intraday_end = "13:30"


        print(f"{YELLOW}é–‹å§‹è£œé½Šä»Šæ—¥ 09:00 åˆ° {full_intraday_end} çš„ä¸€åˆ†Kæ•¸æ“š...{RESET}")

        auto_intraday_data = {}
        initial_api_count = 0
        with ThreadPoolExecutor(max_workers=200) as executor:
            future_to_symbol = {}
            for symbol in symbols_to_analyze:
                if initial_api_count >= 200:
                    time_module.sleep(60)
                    initial_api_count = 0
                yc = yesterday_close_prices.get(symbol, 0)
                if yc == 0:
                    continue
                future = executor.submit(
                    fetch_intraday_data,
                    client=client,
                    symbol=symbol,
                    trading_day=trading_day,
                    yesterday_close_price=yc,
                    start_time="09:00",
                    end_time=full_intraday_end
                )
                future_to_symbol[future] = symbol
                initial_api_count += 1
            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                df = future.result()
                if df.empty:
                    continue
                df = calculate_5min_pct_increase_and_highest(df)
                auto_intraday_data[symbol] = df.to_dict(orient='records')

        # æ¸¬è©¦è¨Šæ¯
        print(f"âœ… [æ­·å²] è£œé½Šå®Œæˆï¼Œè€—æ™‚ï¼š{time_module.perf_counter() - t_fetch_hist:.2f} ç§’")
        t_save_json = time_module.perf_counter()

        save_auto_intraday_data(auto_intraday_data)

        # æ¸¬è©¦è¨Šæ¯
        print(f"ğŸ“ [å¯«æª”] å¯«å…¥ auto_intraday.json å®Œæˆï¼Œè€—æ™‚ï¼š{time_module.perf_counter() - t_save_json:.2f} ç§’")
        '''
        print("å·²æ›´æ–° auto_intraday.jsonã€‚")
        '''
        # ---------- 4. ç›¤ä¸­ä¸»è¿´åœˆ ----------
        print("é–‹å§‹ç›¤ä¸­äº¤æ˜“ç›£æ§ï¼Œè¼¸å…¥ 'Q' è¿”å›ä¸»é¸å–®ï¼š ", end='', flush=True)

        # å•Ÿå‹•éé˜»å¡ Q éµç›£è½èˆ‡é¸å–®è§¸ç™¼
        threading.Thread(target=monitor_quit_key, daemon=True).start()
        threading.Thread(target=check_quit_flag_loop, daemon=True).start()

        # åˆå§‹åŒ–ç›¤ä¸­ç‹€æ…‹
        has_exited = False
        current_position = None
        hold_time = 0
        message_log = []
        already_entered_stocks = []
        stop_loss_triggered = False
        final_check_active = False
        final_check_count = 0
        in_waiting_period = False
        waiting_time = 0
        leader = None
        tracking_stocks = set()
        previous_rise_values = {}
        leader_peak_rise = None
        leader_rise_before_decline = None
        first_condition_one_time = None
        can_trade = True

        exit_live_done = False
        restart_to_post = False

        while not stop_trading:
            now_loop = datetime.now()

            if now_loop.strftime('%H:%M') == '13:26' and not exit_live_done:
                print("\n13:26 æª¢æŸ¥å°šå­˜è§¸åƒ¹å§”è¨—å–®ä¸¦ä¸‹å‡ºå ´å–®")
                exit_trade_live()
                exit_live_done = True

            if market_end < now_loop < post_switch:
                print(f"\nç›®å‰ç‚º {now_loop.strftime('%Y-%m-%d %H:%M:%S')}ï¼Œç›¤å¾Œéæ¸¡æœŸï¼Œç­‰å¾…åˆ‡ç›¤å¾Œæµç¨‹â€¦")
                time_module.sleep((post_switch - now_loop).total_seconds())
                continue

            if now_loop >= post_switch:
                print("\næ”¶ç›¤å¾Œ +1 åˆ†é˜ï¼Œåˆ‡æ›åˆ°ç›¤å¾Œæµç¨‹â€¦")
                restart_to_post = True
                break

            if market_start <= now_loop <= market_end:
                now_sec = datetime.now().second
                time_module.sleep(60 - now_sec)

                fetch_time = datetime.now() - timedelta(minutes=1)
                trading_day = fetch_time.strftime('%Y-%m-%d')
                fetch_time_str = fetch_time.strftime('%H:%M')
                if fetch_time.time() > market_end.time():
                    fetch_time_str = "13:30"
                
                # æ¸¬è©¦è¨Šæ¯
                t_fetch_realtime = time_module.perf_counter()
                print(f"{YELLOW}â± [å³æ™‚] é–‹å§‹å–å¾— {fetch_time_str} çš„ä¸€åˆ†Kè³‡æ–™...{RESET}")

                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                print("\n" + "=" * 50)
                print(f"\n{timestamp} å¸‚å ´é–‹ç›¤ä¸­ï¼Œå–å¾— {fetch_time_str} åˆ†çš„å³æ™‚ä¸€åˆ†Kæ•¸æ“šã€‚")
                print(f"æ­£åœ¨å–å¾—ä¸€åˆ†Kæ•¸æ“šå¾ {fetch_time_str} åˆ° {fetch_time_str}...")

                updated_intraday_data = {}
                with ThreadPoolExecutor(max_workers=200) as executor:
                    future_to_symbol = {}
                    for symbol in symbols_to_analyze:
                        yc = yesterday_close_prices.get(symbol, 0)
                        if yc == 0:
                            continue
                        fut = executor.submit(
                            fetch_intraday_data,
                            client=client,
                            symbol=symbol,
                            trading_day=trading_day,
                            yesterday_close_price=yc,
                            start_time=fetch_time_str,
                            end_time=fetch_time_str
                        )
                        future_to_symbol[fut] = symbol
                    for fut in as_completed(future_to_symbol):
                        sym = future_to_symbol[fut]
                        df = fut.result()
                        if df.empty:
                            continue
                        candle = df.to_dict(orient='records')[0]
                        candle = calculate_5min_pct_increase(candle, auto_intraday_data.get(sym, []))
                        if 'æ¼²åœåƒ¹' in candle:
                            candle['æ¼²åœåƒ¹'] = truncate_to_two_decimals(candle['æ¼²åœåƒ¹'])
                        updated_intraday_data.setdefault(sym, []).append(candle)

                for sym, lst in updated_intraday_data.items():
                    auto_intraday_data.setdefault(sym, []).extend(lst)
                    auto_intraday_data[sym] = auto_intraday_data[sym][-1000:]

                # æ¸¬è©¦è¨Šæ¯
                print(f"âœ… [å³æ™‚] ä¸€åˆ†Kå–å¾—å®Œæˆï¼Œè€—æ™‚ï¼š{time_module.perf_counter() - t_fetch_realtime:.2f} ç§’")
                t_save_json = time_module.perf_counter()

                save_auto_intraday_data(auto_intraday_data)

                # æ¸¬è©¦è¨Šæ¯
                print(f"ğŸ“ [å¯«æª”] å¯«å…¥ auto_intraday.json å®Œæˆï¼Œè€—æ™‚ï¼š{time_module.perf_counter() - t_save_json:.2f} ç§’")
                print("=" * 50)

                process_live_trading_logic(
                    symbols_to_analyze,
                    fetch_time_str,
                    wait_minutes,
                    hold_minutes,
                    message_log,
                    False,
                    has_exited,
                    current_position,
                    hold_time,
                    already_entered_stocks,
                    stop_loss_triggered,
                    final_check_active,
                    final_check_count,
                    in_waiting_period,
                    waiting_time,
                    leader,
                    tracking_stocks,
                    previous_rise_values,
                    leader_peak_rise,
                    leader_rise_before_decline,
                    first_condition_one_time,
                    can_trade,
                    group_positions
                )

        # è‹¥æœ‰åˆ‡æ›åˆ°ç›¤å¾Œ
        if restart_to_post:
            start_trading(mode='post', wait_minutes=wait_minutes, hold_minutes=hold_minutes)
            return

        print("å·²åœæ­¢äº¤æ˜“ï¼Œè¿”å›ä¸»é¸å–®")

    else:  # now >= post_switch
        print(f"ç›®å‰ç‚º {now_str}ï¼Œç›¤å¾Œæ™‚é–“ï¼Œä¸éœ€è¦æ›´æ–°ä»»ä½•æ•¸æ“šï¼Œè¿”å›ä¸»é¸å–®ã€‚")
        return

def login():
    file_path = "shioaji_logic.py"  # è¦æ›´æ–°çš„æª”æ¡ˆè·¯å¾‘

    print('\n' + '=' * 50 + '\n')
    print("ç•¶å‰ api key ç‚ºï¼š" + shioaji_logic.TEST_API_KEY)
    print("ç•¶å‰æ†‘è­‰è·¯å¾‘ç‚ºï¼š" + shioaji_logic.CA_CERT_PATH)
    print("ç•¶å‰æ†‘è­‰å¯†ç¢¼ç‚ºï¼š" + shioaji_logic.CA_PASSWORD)
    print('\n' + '=' * 50)
    print("1. ä¿®æ”¹ api keyã€2. ä¿®æ”¹ api secretã€3. ä¿®æ”¹æ†‘è­‰è·¯å¾‘ã€4. ä¿®æ”¹æ†‘è­‰å¯†ç¢¼")
    api_setting = input("è«‹é¸æ“‡åŠŸèƒ½ï¼š")
    if api_setting == "1":
        new_api_key = input("è«‹è¼¸å…¥æ–°çš„ api keyï¼š")
        update_variable(file_path, "TEST_API_KEY", new_api_key)
    elif api_setting == "2":
        new_api_secret = input("è«‹è¼¸å…¥æ–°çš„ api secretï¼š")
        update_variable(file_path, "TEST_API_SECRET", new_api_secret)
    elif api_setting == "3":
        new_ca_path = input("è«‹è¼¸å…¥æ–°çš„æ†‘è­‰è·¯å¾‘ï¼š")
        update_variable(file_path, "CA_CERT_PATH", new_ca_path, is_raw=True)
    elif api_setting == "4":
        new_ca_password = input("è«‹è¼¸å…¥æ–°çš„æ†‘è­‰å¯†ç¢¼ï¼š")
        update_variable(file_path, "CA_PASSWORD", new_ca_password)
    else:
        print("è«‹è¼¸å…¥åˆæ³•å­—å…ƒ...")
        login()

def update_variable(file_path, var_name, new_value, is_raw=False):
    """
    æ›´æ–°æŒ‡å®šæª”æ¡ˆä¸­ä»¥ var_name é–‹é ­çš„è®Šæ•¸çš„å€¼ã€‚
    è‹¥ is_raw ç‚º Trueï¼Œå‰‡æœƒä»¥ raw å­—ä¸²æ ¼å¼å„²å­˜ï¼ˆä¾‹å¦‚ CA_CERT_PATHï¼‰
    """
    lines = []
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            # å¦‚æœè©²è¡Œä»¥è®Šæ•¸åç¨±é–‹é ­ï¼Œå‰‡æ›¿æ›è©²è¡Œ
            if line.lstrip().startswith(var_name + " ="):
                if is_raw:
                    new_line = f'{var_name} = r"{new_value}"\n'
                else:
                    new_line = f'{var_name} = "{new_value}"\n'
                lines.append(new_line)
            else:
                lines.append(line)
    with open(file_path, "w", encoding="utf-8") as f:
        f.writelines(lines)
    print(f"{var_name} å·²æ›´æ–°ç‚º: {new_value}")
    importlib.reload(shioaji_logic)

#ç™»å…¥
api = sj.Shioaji(simulation=True)
accounts = api.login(api_key = shioaji_logic.TEST_API_KEY, secret_key = shioaji_logic.TEST_API_SECRET)
api.activate_ca(
    ca_path=shioaji_logic.CA_CERT_PATH,
    ca_passwd=shioaji_logic.CA_PASSWORD
)
'''
print("ca_path:", shioaji_logic.CA_CERT_PATH)
print("ca_password:", shioaji_logic.CA_PASSWORD)
'''

# å…¨åŸŸè®Šæ•¸ï¼Œç”¨ä¾†è¨˜éŒ„ä¸Šä¸€æ¬¡å­˜åœ¨æ–¼åœæå§”è¨—å–®ä¸­çš„è‚¡ç¥¨ä»£è™Ÿ
previous_stop_loss_codes = set()
open_positions: dict[str, dict] = {} # â€‘ åªè¦æœ‰é€²å ´å°±å¯«å…¥ï¼›å¹³å€‰å°±åˆªé™¤ï¼ˆç›¤ä¸­æŒå€‰è¡¨ï¼‰ã€‚

def monitor_stop_loss_orders():
    """
    æ¯æ¬¡å‘¼å«æ™‚æª¢æŸ¥ to.conditions çš„å…§å®¹ï¼Œå¦‚æœç™¼ç¾åŸæœ¬å­˜åœ¨çš„åœæå§”è¨—å–®è‚¡ç¥¨ä»£è™Ÿå·²ä¸è¦‹ï¼Œ
    å‰‡æª¢æŸ¥ allow_reentry_after_stop_loss æ˜¯å¦ç‚º Trueï¼Œ
    è‹¥æ˜¯ï¼Œå‰‡å°‡è©²è‚¡ç¥¨æ‰€å±¬æ—ç¾¤çš„ in_position è¨­ç‚º Falseï¼ˆå…è¨±é‡å…¥ï¼‰ã€‚
    """
    global to, group_positions, previous_stop_loss_codes, allow_reentry_after_stop_loss

    # å–å¾—ç›®å‰åœæå§”è¨—å–®çš„è‚¡ç¥¨ä»£è™Ÿé›†åˆ
    if isinstance(to.conditions, dict):
        current_codes = set(to.conditions.keys())
    else:
        # å¦‚æœ to.conditions ä¸æ˜¯å­—å…¸ï¼Œå°±å˜—è©¦å¾æ¯å€‹åœæå–®ç‰©ä»¶ä¸­æå–è‚¡ç¥¨ä»£è™Ÿï¼ˆä¾å¯¦éš›æ ¼å¼èª¿æ•´ï¼‰
        current_codes = set()
        for cond in to.conditions:
            try:
                current_codes.add(cond.order_contract.code)
            except Exception as e:
                print(f"æå–åœæå–®ä»£è™Ÿæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    # èˆ‡ä¸Šä¸€è¼ªè¨˜éŒ„æ¯”è¼ƒï¼Œæ‰¾å‡ºå·²ç§»é™¤çš„è‚¡ç¥¨ä»£è™Ÿ
    removed_codes = previous_stop_loss_codes - current_codes

    if removed_codes:
        if allow_reentry_after_stop_loss:
            nb_matrix_dict = load_nb_matrix_dict()  # å‡è¨­æ­¤å‡½æ•¸èƒ½æ­£ç¢ºè¼‰å…¥ nb_matrix_dict.json
            if "consolidated_symbols" in nb_matrix_dict:
                consolidated_symbols = nb_matrix_dict["consolidated_symbols"]
                for code in removed_codes:
                    # å°‹æ‰¾è©²è‚¡ç¥¨æ‰€åœ¨çš„æ—ç¾¤
                    for group, symbols in consolidated_symbols.items():
                        # å‡è¨­è‚¡ç¥¨ä»£è™Ÿæ ¼å¼ä¸€è‡´
                        if code in symbols:
                            if group in group_positions and group_positions[group] == "å·²é€²å ´":
                                group_positions[group] = False
                                print(f"åœæè§¸ç™¼ï¼šè‚¡ç¥¨ {code} çš„åœæå§”è¨—å–®æ¶ˆå¤±ï¼Œå°‡æ—ç¾¤ {group} çš„ in_position è¨­ç‚º False")
            else:
                print("nb_matrix_dict ä¸­ç¼ºå°‘ 'consolidated_symbols' éµï¼Œç„¡æ³•æ›´æ–°æ—ç¾¤ç‹€æ…‹")
        else:
            print("åœæå§”è¨—å–®æ¶ˆå¤±ï¼Œä½†åœæå†é€²å ´å·²é—œé–‰")
    else:
        print("ç›£æ§ä¸­ï¼šç›®å‰æœªç™¼ç¾ç•°å¸¸...")
        print("=" * 50)

    previous_stop_loss_codes = current_codes.copy()

def monitor_quit_key():
    """èƒŒæ™¯åŸ·è¡Œçš„ Q éµåµæ¸¬å™¨ï¼ŒæŒ‰ä¸‹ Q å°‡ quit_flag['quit'] è¨­ç‚º True"""
    while True:
        if msvcrt.kbhit():
            key = msvcrt.getch().decode("utf-8").upper()
            if key == 'Q':
                quit_flag['quit'] = True

def show_exit_menu():
    """éé˜»å¡åœ°é¡¯ç¤ºé€€å‡ºå¹³å€‰é¸å–®ï¼ˆå¯¦éš›å¹³å€‰é‚è¼¯å¯¦ä½œï¼‰"""
    def _menu():
        print("\n================ æ‰‹å‹•é€€å‡ºé¸å–® ================")
        print("1. ç›´æ¥é€€å‡ºï¼Œä¸å¹³å€‰")
        print("2. å¹³å€‰")
        print("0. è¿”å›ç¨‹å¼")
        choice = input("è«‹è¼¸å…¥é¸é …ï¼š").strip()
        if choice == "1":
            confirm = input("âš ï¸  ç¢ºå®šä¸å¹³å€‰ç›´æ¥é€€å‡ºï¼Ÿ(Y/N)ï¼š").strip().upper()
            if confirm == "Y":
                os._exit(0)
                main_menu()

        elif choice == "2":
            while True:
                list_open_positions()
                print("\nå¹³å€‰é¸é …ï¼š1. å…¨éƒ¨å¹³å€‰  2. é¸æ“‡è‚¡ç¥¨  0. è¿”å›ç¨‹å¼")
                sub = input("è«‹è¼¸å…¥ï¼š").strip()
                if sub == "1":
                    exit_trade_live()
                    os._exit(0)
                    main_menu()
                elif sub == "2":
                    if not open_positions:
                        continue
                    code = input("è¼¸å…¥è¦å¹³å€‰çš„è‚¡ç¥¨ä»£è™Ÿï¼š").strip()
                    if code in open_positions:
                        close_one_stock(code)
                    else:
                        print("ä»£è™Ÿä¸å­˜åœ¨æ–¼æŒå€‰")
                    cont = input("å·²è™•ç†ï¼Œç¹¼çºŒåŸ·è¡Œç¨‹å¼ï¼Ÿ(Y=ç¹¼çºŒ/N=é€€å‡º)ï¼š").strip().upper()
                    if cont == "N":
                        os._exit(0)
                        main_menu()
                elif sub == "0":
                    break
        else:
            print("âŒ ç„¡æ•ˆé¸é …ï¼Œç¹¼çºŒåŸ·è¡Œç¨‹å¼ã€‚")

    threading.Thread(target=_menu, daemon=True).start()

#æ–°å¢ç®¡ç†å¥—ä»¶
to = tp.TouchOrderExecutor(api)

def process_live_trading_logic(
    symbols_to_analyze,
    current_time_str,
    wait_minutes,
    hold_minutes,
    message_log,
    in_position,
    has_exited,
    current_position,
    hold_time,
    already_entered_stocks,
    stop_loss_triggered,
    final_check_active,
    final_check_count,
    in_waiting_period,
    waiting_time,
    leader,
    tracking_stocks,
    previous_rise_values,
    leader_peak_rise,
    leader_rise_before_decline,
    first_condition_one_time,
    can_trade,
    group_positions,
    nb_matrix_path="nb_matrix_dict.json"
):
    """
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      ç›¤ä¸­é€²å ´é‚è¼¯ï¼ˆæ¼²åœé€²å ´ / æ‹‰é«˜é€²å ´ï¼‰
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. è§¸ç™¼æ¢ä»¶  
       â–¸ æ¼²åœé€²å ´ï¼šæœ€æ–° K æ£’ high == æ¼²åœåƒ¹ï¼Œä¸”å‰ä¸€ K æ£’ high < æ¼²åœåƒ¹  
       â–¸ æ‹‰é«˜é€²å ´ï¼š5Â min æ¼²å¹… â‰¥Â 2% ä¸” volume > 1.5Ã—(09:00~09:02 å¹³å‡é‡)

    2. è¿½è¹¤æ¸…å–®ï¼ˆæœ¬ç‰ˆè¦å‰‡ï¼‰  
       â”€ åŠ å…¥æ¢ä»¶ï¼š5Â min æ¼²å¹… â‰¥Â 1.5Â %  
       â”€ åŠ å…¥æ™‚è¨˜éŒ„ join_timeã€base_volã€base_rise

    3. ç­‰å¾…å®Œæˆå¾Œçš„é€²å ´ç¯©é¸  
       â¶ éé ˜æ¼²  
       â· è‡ªåŠ å…¥è¿½è¹¤å¾Œ volume â‰¥Â 1.5Ã—(09:00~09:02 å¹³å‡é‡) æ›¾å‡ºç¾  
       â¸ è‡ªåŠ å…¥è¿½è¹¤å¾Œ rise å…ˆè¦‹é«˜é»ä¸”ä¹‹å¾Œæœªå†å‰µé«˜  
       â¹ ç­‰å¾…æœŸæ»¿ç•¶ä¸‹ rise âˆˆÂ [-2Â %,Â 6Â %]

       â†’ ä¾ rise ç”±å¤§åˆ°å°æ’åºï¼Œå–ä¸­é–“åå¾Œè‚¡ç¥¨ä¸‹å–®  
         (å¸‚åƒ¹ IOC è³£å‡º *dayâ€‘trade short*ï¼ŒTouchPrice åŠ åœæè²·å›)

    4. å…¶ä»–æµç¨‹ï¼ˆé ˜æ¼²åµæ¸¬ / åè½‰ç­‰å¾… / æœ€å¾Œåæ¬¡æª¢æŸ¥ / åœæè¨ˆç®—ï¼‰  
       æ²¿ç”¨èˆŠç‰ˆï¼Œåƒ…å°‡æ¶‰åŠè¿½è¹¤æ¸…å–® & é€²å ´æŒ‘é¸éƒ¨åˆ†ä¾æ–°è¦å‰‡æ”¹å¯«ã€‚
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    """
    # ------------------------------ 0. å‰ç½® ------------------------------- #
    monitor_stop_loss_orders()  # åµæ¸¬åœæè§¸åƒ¹å–®æ˜¯å¦æ¶ˆå¤±

    global capital_per_stock, transaction_fee, transaction_discount, trading_tax
    global price_gap_below_50, price_gap_50_to_100, price_gap_100_to_500
    global price_gap_500_to_1000, price_gap_above_1000
    
    if quit_flag['quit']:
        threading.Thread(target=show_exit_menu, daemon=True).start()
        quit_flag['quit'] = False

    try:
        current_dt = datetime.strptime(current_time_str, "%H:%M")
    except ValueError:
        print(f"æ™‚é–“æ ¼å¼éŒ¯èª¤ï¼š{current_time_str} (é ˆ HH:MM)")
        return

    trading_time = current_dt.time()
    trading_txt  = current_dt.strftime("%H:%M:%S")

    # ---------- è®€ consolidated_symbols ----------
    if not os.path.exists(nb_matrix_path):
        print(f"æ‰¾ä¸åˆ° {nb_matrix_path}")
        return
    with open(nb_matrix_path, "r", encoding="utf-8") as f:
        nb_dict = json.load(f)
    consolidated_symbols = nb_dict.get("consolidated_symbols", {})
    if not isinstance(consolidated_symbols, dict):
        print("consolidated_symbols æ ¼å¼éŒ¯èª¤")
        return

    # ---------- è®€ auto_intraday ----------
    auto_intraday_file = "auto_intraday.json"
    if not os.path.exists(auto_intraday_file):
        print("ç¼ºå°‘ auto_intraday.json")
        return
    with open(auto_intraday_file, "r", encoding="utf-8") as f:
        auto_intraday_data = json.load(f)

    # ---------- å»ºç«‹ DataFrame å¿«å– ----------
    stock_df: dict[str, pd.DataFrame] = {}
    for sym in symbols_to_analyze:
        if sym not in auto_intraday_data:
            stock_df[sym] = pd.DataFrame()
            continue
        df = pd.DataFrame(auto_intraday_data[sym]).copy()
        df["time"] = pd.to_datetime(df["time"], format="%H:%M:%S").dt.time
        df.sort_values("time", inplace=True)
        df.reset_index(drop=True, inplace=True)
        stock_df[sym] = df

    # ---------- é–‹ç›¤å‰ä¸‰åˆ†é˜å‡é‡ ----------
    FIRST3_AVG_VOL: dict[str, float] = {}
    for sym, df in stock_df.items():
        first3 = df[df["time"].astype(str).isin(["09:00:00", "09:01:00", "09:02:00"])]
        FIRST3_AVG_VOL[sym] = first3["volume"].mean() if not first3.empty else 0

    # ------------------------- 1. è§¸ç™¼æª¢æŸ¥ ------------------------------- #
    trigger_list: list[dict] = []   # {symbol, group, condition}

    for grp, syms in consolidated_symbols.items():
        # å·²ç¶“ã€Œè§€å¯Ÿä¸­ã€æˆ–ã€Œå·²é€²å ´ã€çš„æ—ç¾¤ä¸å†æª¢æŸ¥
        if grp in group_positions and group_positions[grp]:
            continue

        for sym in syms:
            if sym not in symbols_to_analyze:
                continue
            df = stock_df[sym]
            if df.empty:
                continue

            row_now = df[df["time"] == trading_time]
            if row_now.empty:
                continue
            row_now = row_now.iloc[0]

            # ---- æ¼²åœé€²å ´è§¸ç™¼ ----
            hit_limit = False
            if row_now["high"] == row_now["æ¼²åœåƒ¹"]:
                prev_time = (datetime.combine(date.today(), trading_time) - timedelta(minutes=1)).time()
                prev_rows = df[df["time"] == prev_time]
                previous_high = prev_rows.iloc[0].get('high', 0.0) if not prev_rows.empty else None
                if previous_high is None:   
                    print(f"{sym} å·²è§¸ç™¼ã€æ¼²åœé€²å ´ã€‘ï¼Œä½†æ‰¾ä¸åˆ°å‰ä¸€æ ¹Kæ£’è³‡æ–™")
                    hit_limit = True
                elif previous_high < row_now["æ¼²åœåƒ¹"]:
                    hit_limit = True

                elif previous_high == row_now["æ¼²åœåƒ¹"]:
                    # æ¸¬è©¦å‰ä¸€æ ¹highå€¼æ˜¯å¦æœ‰æ­£ç¢ºç²å–
                    print(f"{YELLOW}[æ¸¬è©¦] {sym} å‰ä¸€æ ¹Kæ£’çš„ high å€¼ç‚º {previous_high}{RESET}")
                    hit_limit = False


            # ---- æ‹‰é«˜è§¸ç™¼ ----
            pull_up = False
            if row_now["5min_pct_increase"] >= 2.0:
                avgv = FIRST3_AVG_VOL[sym]
                if avgv and row_now["volume"] > 1.5 * avgv:
                    pull_up = True

            if hit_limit or pull_up:
                trigger_list.append({
                    "symbol": sym,
                    "group": grp,
                    "condition": "limit_up" if hit_limit else "pull_up"
                })

    # ---------- å¯«å…¥è§€å¯Ÿç‹€æ…‹ ----------
    for item in trigger_list:
        grp = item["group"]
        cond_txt = "æ¼²åœé€²å ´" if item["condition"] == "limit_up" else "æ‹‰é«˜é€²å ´"
        if grp not in group_positions or not group_positions[grp]:
            group_positions[grp] = {
                "status": "è§€å¯Ÿä¸­",
                "trigger": cond_txt,
                "start_time": datetime.combine(date.today(), trading_time),
                "tracking": {},    # {sym: {...}}
                "leader": None
            }
            msg = f"æ—ç¾¤ {grp} é€²å…¥è§€å¯Ÿä¸­ï¼ˆ{cond_txt}ï¼‰"
            print(msg)
            message_log.append((trading_txt, msg))

    # ------------------------- 2. æ›´æ–°è¿½è¹¤æ¸…å–® --------------------------- #
    for grp, gstat in group_positions.items():
        if not (isinstance(gstat, dict) and gstat["status"] == "è§€å¯Ÿä¸­"):
            continue

        track = gstat.get("tracking", {})
        for sym in consolidated_symbols[grp]:
            df = stock_df[sym]
            if df.empty:
                continue
            row_now = df[df["time"] == trading_time]
            if row_now.empty:
                continue
            row_now = row_now.iloc[0]

            # åŠ å…¥æ¢ä»¶ï¼š5min_pct_increase â‰¥ 1.5 %
            if row_now["5min_pct_increase"] >= 1.5:
                if sym not in track:
                    track[sym] = {
                        "join_time": datetime.combine(date.today(), trading_time),
                        "base_vol": row_now["volume"],
                        "base_rise": row_now["rise"]
                    }
                    msg = f"{sym} åŠ å…¥ {grp} è¿½è¹¤æ¸…å–®ï¼ˆ5minâ†‘1.5%ï¼‰"
                    print(msg)
        gstat["tracking"] = track

    # ----------------------- 3. é ˜æ¼²è™•ç†ï¼ˆæ‹‰é«˜ï¼‰ ------------------------ #
    for grp, gstat in group_positions.items():
        if not (isinstance(gstat, dict) and gstat["status"] == "è§€å¯Ÿä¸­"):
            continue
        if gstat["trigger"] != "æ‹‰é«˜é€²å ´":
            continue

        track = gstat["tracking"]
        if not track:
            continue

        # ç›®å‰ rise æœ€å¤§è€… = é ˜æ¼²
        max_sym = None
        max_rise = None
        for sym in track:
            df = stock_df[sym]
            row_now = df[df["time"] == trading_time]
            if row_now.empty:
                continue
            rise_now = row_now.iloc[0]["rise"]
            if max_rise is None or rise_now > max_rise:
                max_rise = rise_now
                max_sym  = sym

        # è‹¥é¦–æ¬¡ç¢ºç«‹é ˜æ¼²
        if gstat.get("leader") is None:
            gstat["leader"] = max_sym
            msg = f"æ‹‰é«˜é€²å ´ {grp} ç¢ºç«‹é ˜æ¼²ï¼š{max_sym}"
            print(msg)
            message_log.append((trading_txt, msg))
        else:
            # è‹¥é ˜æ¼²æ›¿æ›
            if max_sym and max_sym != gstat["leader"]:
                msg = f"æ‹‰é«˜é€²å ´ {grp} é ˜æ¼²æ›¿æ›ï¼š{gstat['leader']} â†’ {max_sym}"
                print(msg)
                message_log.append((trading_txt, msg))
                gstat["leader"] = max_sym

        # ---- é ˜æ¼²åè½‰ â†’ é€²å…¥ç­‰å¾… ----
        lead_sym = gstat["leader"]
        if not lead_sym:
            continue
        df_lead = stock_df[lead_sym]
        idx_now = df_lead[df_lead["time"] == trading_time].index
        if idx_now.empty:
            continue
        idx_now = idx_now[0]
        if idx_now - 1 >= 0:
            high_now = df_lead.loc[idx_now, "high"]
            high_pre = df_lead.loc[idx_now - 1, "high"]
            if high_now <= high_pre:
                # é–‹å§‹ç­‰å¾…
                if "wait_start" not in gstat:
                    gstat["wait_start"] = now_full = datetime.combine(date.today(), trading_time)
                    gstat["wait_counter"] = 0
                    gstat["leader_reversal_rise"] = df_lead.loc[idx_now, "rise"]
                    msg = f"æ‹‰é«˜é€²å ´ {grp} é ˜æ¼² {lead_sym} åè½‰ï¼Œé–‹å§‹ç­‰å¾…"
                    print(msg)
                    message_log.append((trading_txt, msg))

    # --------- è‹¥è™•æ–¼ç­‰å¾…éšæ®µï¼Œæ¯åˆ†é˜ç´¯åŠ ä¸¦å°ç‹€æ…‹ ---------
    for grp, gstat in group_positions.items():
        if not (isinstance(gstat, dict) and gstat["status"] == "è§€å¯Ÿä¸­"):
            continue
        if gstat["trigger"] != "æ‹‰é«˜é€²å ´":
            continue
        if "wait_start" in gstat:
            gstat["wait_counter"] += 1
            print(f"æ‹‰é«˜é€²å ´ {grp} ç­‰å¾…ç¬¬ {gstat['wait_counter']} åˆ†é˜")

    # ---------------- 4. ç­‰å¾…å®Œæˆ â†’ ç¯©é¸è‚¡ç¥¨é€²å ´ ---------------- #
    def _vol_break(sym: str, join_time: datetime) -> bool:
        df = stock_df[sym]
        if df.empty:
            return False
        avgv = FIRST3_AVG_VOL[sym]
        if avgv == 0:
            return False
        later = df[df["time"] >= join_time.time()]
        return (later["volume"] >= 1.5 * avgv).any()

    def _rise_peak_flat(sym: str, join_time: datetime) -> bool:
        df = stock_df[sym]
        if df.empty:
            return False
        sub = df[df["time"] >= join_time.time()]
        if sub.empty:
            return False
        peak_idx = sub["rise"].idxmax()
        peak_val = sub.loc[peak_idx, "rise"]
        later = sub[sub.index > peak_idx]
        return (later["rise"] <= peak_val).all()

    groups_ready = []
    now_full = datetime.combine(date.today(), trading_time)
    for grp, gstat in group_positions.items():
        if not (isinstance(gstat, dict) and gstat["status"] == "è§€å¯Ÿä¸­"):
            continue
        elapsed = (now_full - gstat["start_time"]).total_seconds() / 60
        if elapsed >= wait_minutes:
            groups_ready.append(grp)

    for grp in groups_ready:
        gstat  = group_positions[grp]
        track  = gstat["tracking"]
        leader_sym = gstat.get("leader")

        eligible: list[dict] = []
        for sym, info in track.items():
            if sym == leader_sym:
                continue
            if not _vol_break(sym, info["join_time"]):
                continue
            if not _rise_peak_flat(sym, info["join_time"]):
                continue
            df = stock_df[sym]
            row_now = df[df["time"] == trading_time]
            if row_now.empty:
                continue
            rise_now = row_now.iloc[0]["rise"]
            if not (-2 <= rise_now <= 6):
                continue
            entry_price = row_now.iloc[0]["close"]
            if entry_price > capital_per_stock * 1.5:
                msg = f"âš ï¸ æ’é™¤ {sym}ï¼Œè‚¡åƒ¹ {entry_price:.2f} è¶…éè³‡é‡‘ä¸Šé™ {capital_per_stock*1.5:.2f}"
                print(msg)
                message_log.append((trading_txt, msg))
                continue

            eligible.append({
                "symbol": sym,
                "rise": rise_now,
                "row": row_now.iloc[0]
            })

        if not eligible:
            msg = f"{grp} ç­‰å¾…å®Œæˆï¼Œä½†ç„¡ç¬¦åˆæ¢ä»¶è‚¡ç¥¨ â†’ å–æ¶ˆè§€å¯Ÿ"
            print(msg)
            message_log.append((trading_txt, msg))
            group_positions[grp] = False
            continue

        eligible.sort(key=lambda x: x["rise"], reverse=True)
        chosen = eligible[len(eligible)//2]

        # ------------------- ä¸‹å–® -------------------
        
        row      = chosen["row"]
        entry_px = row["close"]
        shares   = round((capital_per_stock * 10000) / (entry_px * 1000))
        sell_amt = shares * entry_px * 1000
        fee      = int(sell_amt * (transaction_fee * 0.01) * (transaction_discount * 0.01))
        tax      = int(sell_amt * (trading_tax * 0.01))

        # åœæåƒ¹è¨ˆç®—
        if entry_px < 10:
            gap, tick = price_gap_below_50, 0.01
        elif entry_px < 50:
            gap, tick = price_gap_50_to_100, 0.05
        elif entry_px < 100:
            gap, tick = price_gap_50_to_100, 0.1
        elif entry_px < 500:
            gap, tick = price_gap_100_to_500, 0.5
        elif entry_px < 1000:
            gap, tick = price_gap_500_to_1000, 1
        else:
            gap, tick = price_gap_above_1000, 5

        highest_on_entry = row["highest"] or entry_px
        if (highest_on_entry - entry_px) * 1000 < gap:
            stop_type = "price_difference"
            stop_thr  = entry_px + gap/1000
        else:
            stop_type = "over_high"
            stop_thr  = highest_on_entry + tick

        current_position = {
            "symbol": chosen["symbol"],
            "shares": shares,
            "entry_price": entry_px,
            "sell_cost": sell_amt,
            "entry_fee": fee,
            "tax": tax,
            "entry_time": trading_txt,
            "current_price_gap": gap,
            "tick_unit": tick,
            "highest_on_entry": highest_on_entry,
            "stop_loss_type": stop_type,
            "stop_loss_threshold": stop_thr
        }

        open_positions[chosen['symbol']] = {'entry_price': entry_px, 'shares': shares} # ï¼å°‡æœ‰çœŸæ­£é€å‡ºå–®çš„è‚¡ç¥¨åŠ å…¥åˆ°è¡¨ä¸­

        # --- ä¸‹å¸‚åƒ¹ IOC è³£å‡ºå–®ï¼ˆåˆ¸å…ˆè³£ï¼‰ ---
        stock_code_int = int(chosen["symbol"])
        contract = getattr(api.Contracts.Stocks.TSE, "TSE" + str(stock_code_int))
        order = api.Order(
            price=0,
            quantity=shares,
            action=sj.constant.Action.Sell,
            price_type=sj.constant.StockPriceType.MKT,
            order_type=sj.constant.OrderType.IOC,
            order_lot=sj.constant.StockOrderLot.Common,
            daytrade_short=True,
            account=api.stock_account
        )
        trade = api.place_order(contract, order)

        # --- TouchPrice åœæè²·å› ---
        t_cmd = tp.TouchCmd(
            code=f"{stock_code_int}",
            close=tp.Price(price=stop_thr, trend="Equal")
        )
        o_cmd = tp.OrderCmd(
            code=f"{stock_code_int}",
            order=sj.Order(
                price=0,
                quantity=shares,
                action="Buy",
                order_type="ROD",
                price_type="MKT"
            )
        )
        tcond = tp.TouchOrderCond(t_cmd, o_cmd)
        to.add_condition(tcond)

        msg = (
            f"{GREEN}é€²å ´ï¼{chosen['symbol']}  {shares}å¼µ  "
            f"æˆäº¤åƒ¹ {entry_px:.2f}  åœæåƒ¹ {stop_thr:.2f}{RESET}"
        )
        print(msg)
        message_log.append((trading_txt, msg))

        in_position            = True
        group_positions[grp]   = "å·²é€²å ´"
        leader                 = None
        tracking_stocks.clear()
        previous_rise_values.clear()

    # ------------------ 5. ä¾æ™‚é–“æ’åºåˆ—å°è¨Šæ¯ ------------------- #
    message_log.sort(key=lambda x: x[0])
    for t, m in message_log:
        print(f"[{t}] {m}")
    message_log.clear()

#ç›¤ä¸­13:30å‡ºå ´
def exit_trade_live():
    """
    æ­¤å‡½æ•¸ä¾æ“šè¨­å®šï¼Œæ–¼ 13:26 æ™‚é€²è¡Œå‡ºå ´å‹•ä½œï¼š
      1. å¾å…¨åŸŸè®Šæ•¸ to ä¸­å–å¾—æ‰€æœ‰å°šå­˜çš„è§¸åƒ¹å§”è¨—å–®ï¼ˆto.conditionsï¼‰
      2. ä¾æ“šæ¯å€‹è‚¡ç¥¨ä»£è™Ÿçš„æ‰€æœ‰å§”è¨—å–®ï¼Œç´¯åŠ å–å‡ºé€²å ´å¼µæ•¸ï¼ˆquantityï¼‰ï¼Œå½¢æˆ exit_data å­—å…¸
      3. å°‡ exit_data å¯«å…¥æœ¬åœ°æª”æ¡ˆ "enter_exit.json"
      4. é‡æ–°è®€å– "enter_exit.json" çš„è³‡æ–™
      5. å° exit_data ä¸­æ¯ä¸€ç­†è³‡æ–™ï¼Œåˆ©ç”¨è‚¡ç¥¨ä»£è™Ÿèˆ‡é€²å ´å¼µæ•¸å»ºç«‹å‡ºå ´å§”è¨—å–®ä¸¦ä¸‹å–®
      6. åˆªé™¤æ‰€æœ‰å°šå­˜çš„è§¸åƒ¹å§”è¨—å–®
      7. åŒæ­¥å¾ open_positions ä¸­ç§»é™¤å·²å¹³å€‰çš„è‚¡ç¥¨
    """
    global open_positions

    # 1. å–å¾—æ‰€æœ‰å°šå­˜çš„è§¸åƒ¹å§”è¨—å–®
    conditions_dict = to.conditions
    exit_data = {}

    # 2. éæ­·æ¯å€‹è‚¡ç¥¨ä»£è™ŸåŠå…¶å§”è¨—å–®åˆ—è¡¨ï¼Œç´¯åŠ é€²å ´å¼µæ•¸
    for stock_code, cond_list in conditions_dict.items():
        total_quantity = 0
        for cond in cond_list:
            try:
                qty = getattr(cond.order, 'quantity', 0)
                total_quantity += int(qty)
            except Exception as e:
                print(f"è®€å–è‚¡ç¥¨ {stock_code} çš„æ•¸é‡æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        if total_quantity > 0:
            exit_data[stock_code] = total_quantity

    # 3. å°‡ exit_data å¯«å…¥ "enter_exit.json"
    try:
        with open("enter_exit.json", "w", encoding="utf-8") as f:
            json.dump(exit_data, f, ensure_ascii=False, indent=4)
        print("å·²å°‡ç•¶å‰è§¸åƒ¹å§”è¨—å–®çš„è‚¡ç¥¨ä»£è™Ÿå’Œé€²å ´å¼µæ•¸å„²å­˜è‡³ enter_exit.json:")
        print(exit_data)
    except Exception as e:
        print(f"å¯«å…¥ enter_exit.json æª”æ¡ˆå¤±æ•—ï¼š{e}")
        return

    # 4. è®€å–æœ€æ–°çš„ exit data
    try:
        with open("enter_exit.json", "r", encoding="utf-8") as f:
            exit_info = json.load(f)
    except Exception as e:
        print(f"è®€å– enter_exit.json æª”æ¡ˆå¤±æ•—ï¼š{e}")
        return

    if not exit_info:
        print("enter_exit.json ä¸­æ²’æœ‰è§¸åƒ¹å§”è¨—å–®è³‡æ–™ï¼Œçµ‚æ­¢å‡ºå ´ç¨‹åºã€‚")
        return

    # 5. å°æ¯ç­† exit_info ä¸­çš„è³‡æ–™ï¼Œå»ºç«‹å‡ºå ´å§”è¨—å–®ä¸¦ä¸‹å–®
    for stock_code, shares in exit_info.items():
        try:
            # å–å¾— contract ç‰©ä»¶ï¼Œä¾‹å¦‚ "TSE2330"
            contract = getattr(api.Contracts.Stocks.TSE, "TSE" + str(stock_code))
            limit_up_price = contract.limit_up

            # å»ºç«‹é™åƒ¹è²·é€²çš„å§”è¨—å–® (ROC æ¢ä»¶)
            order = api.Order(
                action=sj.constant.Action.Buy,
                price=limit_up_price,
                quantity=shares,
                price_type=sj.constant.StockPriceType.LMT,
                order_type=sj.constant.OrderType.ROC,
                order_lot=sj.constant.StockOrderLot.Common,
                account=api.stock_account
            )
            trade = api.place_order(contract, order)
            print(f"{RED}ä¸‹å–®å‡ºå ´ï¼šè‚¡ç¥¨ {stock_code}ï¼Œæ•¸é‡ {shares} å¼µï¼›åƒ¹æ ¼è¨­å®šç‚ºæ¼²åœåƒ¹ {limit_up_price}{RESET}")

            # 7. åŒæ­¥å¾ open_positions ç§»é™¤å·²å¹³å€‰çš„è‚¡ç¥¨
            open_positions.pop(stock_code, None)

        except Exception as e:
            print(f"è™•ç†è‚¡ç¥¨ {stock_code} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    # 6. åˆªé™¤æ‰€æœ‰å°šå­˜çš„è§¸åƒ¹å§”è¨—å–®
    for stock_code, cond_list in list(conditions_dict.items()):
        for cond in cond_list:
            try:
                to.delete_condition(cond)
            except Exception as e:
                print(f"åˆªé™¤è‚¡ç¥¨ {stock_code} çš„è§¸åƒ¹å§”è¨—å–®æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    print(f"{RED}å‡ºå ´å§”è¨—å–®å·²å…¨éƒ¨ä¸‹å–®ï¼Œä¸¦åˆªé™¤æ‰€æœ‰è§¸åƒ¹å§”è¨—å–®ã€‚{RESET}")

def list_open_positions():
    if not open_positions:
        print(f"{YELLOW}ç›®å‰æ²’æœ‰ä»»ä½•æŒå€‰{RESET}")
        return
    print("\n========== ç›®å‰æŒå€‰ ==========")
    for i, (c, info) in enumerate(open_positions.items(), 1):
        print(f"{i}. {c:<6} {get_stock_name(c):<8} é€²å ´åƒ¹={info['entry_price']}  å¼µæ•¸={info['shares']}")
    print("=" * 29)

def close_one_stock(code: str):
    """åˆªè©²è‚¡æ‰€æœ‰è§¸åƒ¹å–® + ä»¥æ¼²åœåƒ¹ ROC å¸‚åƒ¹è²·å›"""
    conds = to.conditions.get(code, [])
    qty   = sum(getattr(c.order, 'quantity', 0) for c in conds)
    if qty == 0:
        print(f"âš ï¸  {code} å·²ç„¡å§”è¨— / æŒå€‰")
        return
    try:
        contract = getattr(api.Contracts.Stocks.TSE, f"TSE{code}")
        api.place_order(contract, api.Order(
            action=sj.constant.Action.Buy,
            price=contract.limit_up,
            quantity=qty,
            price_type=sj.constant.StockPriceType.LMT,
            order_type=sj.constant.OrderType.ROC,
            order_lot=sj.constant.StockOrderLot.Common,
            account=api.stock_account
        ))
        print(f"{GREEN}å·²å¹³å€‰ {code}  å…± {qty} å¼µ{RESET}")
    except Exception as e:
        print(f"å¹³å€‰ {code} æ™‚éŒ¯èª¤ï¼š{e}")
    for c in conds:
        to.delete_condition(c)
    to.conditions.pop(code, None)
    open_positions.pop(code, None)

def quick_manual_exit() -> bool:
    """
    å½ˆå‡º Q éµé¸å–®ã€‚
    å›å‚³ True  â†’ ç«‹åˆ»é›¢é–‹ start_trading çš„ç›¤ä¸­ while è¿´åœˆ
    å›å‚³ False â†’ ä»€éº¼éƒ½ä¸åšï¼Œç¹¼çºŒç›£æ§
    """
    print("\n================ æ‰‹å‹•é€€å‡ºé¸å–® ================")
    print("1. ç›´æ¥é€€å‡ºï¼Œä¸å¹³å€‰")
    print("2. å¹³å€‰")
    print("0. è¿”å›ç¨‹å¼")
    choice = input("è«‹è¼¸å…¥é¸é …ï¼š").strip()
    # --- ç›´æ¥é€€ ---
    if choice == "1":
        return input("âš ï¸  ç¢ºå®šä¸å¹³å€‰ç›´æ¥é€€å‡ºï¼Ÿ(Y/N)ï¼š").strip().upper() == "Y"
    # --- å¹³å€‰ ---
    if choice == "2":
        while True:
            list_open_positions()
            print("\nå¹³å€‰é¸é …ï¼š1. å…¨éƒ¨å¹³å€‰  2. é¸æ“‡è‚¡ç¥¨  0. è¿”å›ç¨‹å¼")
            sub = input("è«‹è¼¸å…¥ï¼š").strip()
            if sub == "1":
                exit_trade_live()
                return True
            if sub == "2":
                if not open_positions:
                    continue
                code = input("è¼¸å…¥è¦å¹³å€‰çš„è‚¡ç¥¨ä»£è™Ÿï¼š").strip()
                if code in open_positions:
                    close_one_stock(code)
                else:
                    print("ä»£è™Ÿä¸å­˜åœ¨æ–¼æŒå€‰")
                # æ˜¯å¦ç¹¼çºŒï¼Ÿ
                cont = input("å·²è™•ç†ï¼Œç¹¼çºŒåŸ·è¡Œç¨‹å¼ï¼Ÿ(Y=ç¹¼çºŒ/N=é€€å‡º)ï¼š").strip().upper()
                if cont == "N":
                    return True
            if sub == "0":
                return False
    # --- è¿”å›ç¨‹å¼ ---
    return False
    
def truncate_to_two_decimals(value):
    if isinstance(value, float):
        return math.floor(value * 100) / 100
    return value

def calculate_5min_pct_increase(new_candle, existing_candles):
    new_candle['5min_pct_increase'] = 0.0
    all_candles = existing_candles + [new_candle]
    num_existing_candles = len(existing_candles)
    if num_existing_candles == 0:
        new_candle['5min_pct_increase'] = 0.0
    else:
        if num_existing_candles < 4:
            relevant_candles = all_candles
        else:
            relevant_candles = existing_candles[-4:] + [new_candle]

        close_prices = [float(c['close']) for c in relevant_candles if c.get('close') is not None]

        if len(close_prices) < 2:
            new_candle['5min_pct_increase'] = 0.0
        else:
            max_close = max(close_prices)
            min_close = min(close_prices)
            index_max = close_prices.index(max_close)
            index_min = close_prices.index(min_close)

            if index_max > index_min:
                pct_increase = ((max_close - min_close) / min_close) * 100
            else:
                pct_increase = ((min_close - max_close) / max_close) * 100

            new_candle['5min_pct_increase'] = round(pct_increase, 2)
    return new_candle

def save_auto_intraday_data(auto_intraday_data):
    try:
        with open('auto_intraday.json', 'wb') as f:
            f.write(orjson.dumps(auto_intraday_data, option=orjson.OPT_NON_STR_KEYS))
        print(f"{YELLOW}âœ… å·²å„²å­˜ auto_intraday.json{RESET}")
    except Exception as e:
        print(f"{YELLOW}âŒ å„²å­˜ auto_intraday.json æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}{RESET}")

def update_kline_data_menu():
    while True:
        print("\næ›´æ–°Kç·šæ•¸æ“šé¸å–®ï¼š")
        print("1. æ›´æ–°Kç·šæ•¸æ“š")
        print("2. æŸ¥çœ‹Kç·šæ•¸æ“š")
        print("0. è¿”å›ä¸»é¸å–®")
        choice = input("è«‹è¼¸å…¥é¸é …ï¼š")
        if choice == '1':
            update_kline_data()
        elif choice == '2':
            view_kline_data()
        elif choice == '0':
            main_menu()
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

def convert_datetime_to_str(obj):
    if isinstance(obj, dict):
        return {k: convert_datetime_to_str(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_datetime_to_str(element) for element in obj]
    elif isinstance(obj, (datetime, pd.Timestamp, time)):
        return obj.isoformat()
    else:
        return obj

def update_kline_data():
    client, api_key = init_fugle_client()
    matrix_dict_analysis = load_matrix_dict_analysis()
    if not matrix_dict_analysis:
        print("æ²’æœ‰ä»»ä½•æ—ç¾¤è³‡æ–™ï¼Œè«‹å…ˆç®¡ç†æ—ç¾¤ã€‚")
        return

    print("æ­£åœ¨æ›´æ–°è™•ç½®è‚¡æ¸…å–®...")
    fetch_disposition_stocks(client, matrix_dict_analysis)
    print("è™•ç½®è‚¡æ¸…å–®å·²æ›´æ–°ã€‚")

    disposition_stocks = load_disposition_stocks()
    symbols_to_analyze = [sym for group in matrix_dict_analysis.values() for sym in group if sym not in disposition_stocks]

    # ===== â‘  æ›´æ–°æ—¥ K ç·šè³‡æ–™ =====
    print("âœ… é–‹å§‹æ›´æ–°æ—¥Kç·šæ•¸æ“šè‡³ daily_kline_data.json...")

    existing_daily_kline_data = {}
    if os.path.exists('daily_kline_data.json'):
        with open('daily_kline_data.json', 'r', encoding='utf-8') as f:
            try:
                existing_daily_kline_data = json.load(f)
            except json.JSONDecodeError:
                existing_daily_kline_data = {}
    else:
        print("âš ï¸ auto_daily.json ä¸å­˜åœ¨ï¼Œå°‡å»ºç«‹æ–°æª”æ¡ˆã€‚")

    data_is_same = True
    max_symbols_to_fetch = 20
    symbols_fetched = 0
    initial_api_count = 0

    for symbol in symbols_to_analyze[:max_symbols_to_fetch]:
        if initial_api_count >= 55:
            print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
            time_module.sleep(60)
            initial_api_count = 0

        daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
        initial_api_count += 1

        if daily_kline_df.empty:
            print(f"âŒ ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
            continue

        daily_kline_data = daily_kline_df.to_dict(orient='records')
        existing_data = existing_daily_kline_data.get(symbol)
        if existing_data != daily_kline_data:
            data_is_same = False
            print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
            existing_daily_kline_data[symbol] = daily_kline_data
        else:
            print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")
        symbols_fetched += 1

    if not data_is_same:
        print("ğŸ”„ ç™¼ç¾è³‡æ–™æœ‰ç•°å‹•ï¼Œé–‹å§‹æ›´æ–°å‰©é¤˜è‚¡ç¥¨...")
        remaining_symbols = symbols_to_analyze[max_symbols_to_fetch:]
        for symbol in remaining_symbols:
            if initial_api_count >= 55:
                print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
                time_module.sleep(60)
                initial_api_count = 0

            daily_kline_df = fetch_daily_kline_data(client, symbol, days=2)
            initial_api_count += 1

            if daily_kline_df.empty:
                print(f"âŒ ç„¡æ³•å–å¾— {symbol} çš„æ—¥Kæ•¸æ“šï¼Œè·³éã€‚")
                continue

            daily_kline_data = daily_kline_df.to_dict(orient='records')
            existing_data = existing_daily_kline_data.get(symbol)
            if existing_data != daily_kline_data:
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ä¸åŒï¼Œå°‡æ›´æ–°è³‡æ–™ã€‚")
                existing_daily_kline_data[symbol] = daily_kline_data
            else:
                print(f"{symbol} çš„æ—¥Kæ•¸æ“šèˆ‡ç¾æœ‰è³‡æ–™ç›¸åŒï¼Œè·³éæ›´æ–°ã€‚")

    with open('daily_kline_data.json', 'w', encoding='utf-8') as f:
        json.dump(existing_daily_kline_data, f, indent=4, ensure_ascii=False)

    print("âœ… æ—¥Kç·šæ•¸æ“šå·²å¯«å…¥ daily_kline_data.jsonã€‚")

    # ===== â‘¡ æ›´æ–°ä¸€åˆ† K ç·šè³‡æ–™ =====
    print("âœ… é–‹å§‹æ›´æ–°ä¸€åˆ†Kç·šè³‡æ–™è‡³ intraday_kline_data.json...")
    intraday_kline_data = {}
    count = 0
    current_time = datetime.now()
    if current_time.hour < 13 or (current_time.hour == 13 and current_time.minute < 30):
        end_time_str = (current_time - timedelta(minutes=1)).strftime('%H:%M')
    else:
        end_time_str = "13:30"

    for symbol in symbols_to_analyze:
        if count >= 55:
            print("å·²é”åˆ°55æ¬¡APIè«‹æ±‚ï¼Œä¼‘æ¯1åˆ†é˜...")
            time_module.sleep(60)
            count = 0

        daily_data = existing_daily_kline_data.get(symbol, [])
        if len(daily_data) < 2:
            print(f"{symbol} æ—¥Kè³‡æ–™ä¸è¶³ï¼Œç„¡æ³•åˆ¤æ–·æ˜¨æ”¶ï¼Œè·³éã€‚")
            continue
        yesterday_close_price = daily_data[1].get('close', 0)
        

        intraday_df = fetch_intraday_data(
            client=client,
            symbol=symbol,
            trading_day=datetime.today().strftime('%Y-%m-%d'),
            yesterday_close_price=yesterday_close_price,
            start_time="09:00",
            end_time=end_time_str
        )
        count += 1

        if intraday_df.empty:
            print(f"ç„¡æ³•å–å¾— {symbol} çš„ä¸€åˆ†Kæ•¸æ“šï¼Œè·³éã€‚")
            continue
        intraday_df = calculate_5min_pct_increase_and_highest(intraday_df)
        intraday_kline_data[symbol] = intraday_df.to_dict(orient='records')
        print(f"{symbol} çš„ä¸€åˆ†Kè³‡æ–™å·²åŠ å…¥ã€‚")

    intraday_kline_data_str = convert_datetime_to_str(intraday_kline_data)
    with open('intraday_kline_data.json', 'w', encoding='utf-8') as f:
        json.dump(intraday_kline_data_str, f, indent=4, ensure_ascii=False, default=str)
    print("âœ… ä¸€åˆ†Kç·šè³‡æ–™å·²å¯«å…¥ intraday_kline_data.jsonã€‚")

    # ===== â‘¢ è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£ä¸¦å„²å­˜ =====
    mt_matrix_dict = {}
    for group, symbols in matrix_dict_analysis.items():
        stock_data_list = []
        for symbol in symbols:
            if symbol in intraday_kline_data:
                df = pd.DataFrame(intraday_kline_data[symbol])
                if 'symbol' not in df.columns:
                    df['symbol'] = symbol
                stock_data_list.append(df)

        if stock_data_list:
            print(f"æ­£åœ¨è¨ˆç®—æ—ç¾¤ {group} çš„ç›¸ä¼¼åº¦...")
            similarity_df = calculate_kline_similarity(stock_data_list)
            similarity_df = similarity_df[similarity_df['similarity_score'] > 0.3]

            if similarity_df.empty:
                print(f"æ—ç¾¤ {group} æ²’æœ‰ç›¸ä¼¼åº¦å¤§æ–¼ 0.3 çš„è‚¡ç¥¨çµ„åˆã€‚")
                continue

            similarity_records = similarity_df.to_dict(orient='records')
            for record in similarity_records:
                record['group'] = group

            mt_matrix_dict[group] = similarity_records
            print(f"{group} çš„ç›¸ä¼¼åº¦è¨ˆç®—å®Œæˆä¸¦åŠ å…¥ mt_matrix_dictã€‚")

    with open('mt_matrix_dict.json', 'w', encoding='utf-8') as f:
        json.dump(mt_matrix_dict, f, indent=4, ensure_ascii=False, default=str)
    print("âœ… ç›¸ä¼¼åº¦çŸ©é™£å·²å„²å­˜è‡³ mt_matrix_dict.jsonã€‚")

    consolidate_and_save_stock_symbols()
    print("âœ… è‚¡ç¥¨ä»£è™Ÿå·²çµ±æ•´ä¸¦å„²å­˜è‡³ nb_matrix_dict.jsonã€‚")

def view_kline_data():
    if not os.path.exists('intraday_kline_data.json'):
        print("å°šæœªæ›´æ–°ä¸€åˆ†Kæ•¸æ“šï¼Œè«‹å…ˆæ›´æ–°Kç·šæ•¸æ“šã€‚")
        return
    with open('intraday_kline_data.json', 'r', encoding='utf-8') as f:
        intraday_kline_data = json.load(f)
    
    for symbol, data in intraday_kline_data.items():
        print(f"\nè‚¡ç¥¨ä»£è™Ÿï¼š{symbol} çš„ä¸€åˆ†Kæ•¸æ“šï¼š")
        df = pd.DataFrame(data)
        if df.empty:
            print("æ²’æœ‰è³‡æ–™ã€‚")
            continue
        
        if 'time' in df.columns:
            try:
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore", UserWarning)
                    df['time'] = pd.to_datetime(df['time'])
            except Exception as e:
                print(f"è½‰æ›æ™‚é–“æ¬„ä½æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                continue
        
        print(df)

def save_settings():
    with open('settings.json', 'w', encoding='utf-8') as f:
        json.dump({
            'capital_per_stock': capital_per_stock,
            'transaction_fee': transaction_fee,
            'transaction_discount': transaction_discount,
            'trading_tax': trading_tax,
            'below_50': below_50,
            'price_gap_50_to_100': price_gap_50_to_100,
            'price_gap_100_to_500': price_gap_100_to_500,
            'price_gap_500_to_1000': price_gap_500_to_1000,
            'price_gap_above_1000': price_gap_above_1000,
            'allow_reentry_after_stop_loss': allow_reentry_after_stop_loss
        }, f, indent=4)

def load_settings():
    global capital_per_stock, transaction_fee, transaction_discount, trading_tax
    global below_50, price_gap_50_to_100, price_gap_100_to_500, price_gap_500_to_1000, price_gap_above_1000
    global allow_reentry_after_stop_loss
    if os.path.exists('settings.json'):
        with open('settings.json', 'r', encoding='utf-8') as f:
            settings = json.load(f)
            capital_per_stock = settings.get('capital_per_stock', 0)
            transaction_fee = settings.get('transaction_fee', 0)
            transaction_discount = settings.get('transaction_discount', 0)
            trading_tax = settings.get('trading_tax', 0)
            below_50 = settings.get('below_50', 0)
            price_gap_50_to_100 = settings.get('price_gap_50_to_100', 0)
            price_gap_100_to_500 = settings.get('price_gap_100_to_500', 0)
            price_gap_500_to_1000 = settings.get('price_gap_500_to_1000', 0)
            price_gap_above_1000 = settings.get('price_gap_above_1000', 0)
            allow_reentry_after_stop_loss = settings.get('allow_reentry_after_stop_loss', False)
    else:
        capital_per_stock = 1000
        transaction_fee = 0.1425
        transaction_discount = 20.0
        trading_tax = 0.15
        below_50 = 500
        price_gap_50_to_100 = 1000
        price_gap_100_to_500 = 2000
        price_gap_500_to_1000 = 3000
        price_gap_above_1000 = 5000
        allow_reentry_after_stop_loss = False

def settings_menu():
    global capital_per_stock, transaction_fee, transaction_discount, trading_tax
    global below_50, price_gap_50_to_100, price_gap_100_to_500, price_gap_500_to_1000, price_gap_above_1000
    global allow_reentry_after_stop_loss
    while True:
        print("\nè¨­å®šé¸å–®ï¼š")
        print(f"1. è¨­å®šæ¯æª”è‚¡ç¥¨æŠ•å…¥è³‡æœ¬é¡ï¼ˆç›®å‰ç‚º {capital_per_stock} è¬å…ƒï¼‰")
        print(f"2. æ‰‹çºŒè²»è¨­å®šï¼Œç›®å‰ç‚º {transaction_fee}%")
        print(f"3. æ‰‹çºŒè²»æŠ˜æ•¸è¨­å®šï¼Œç›®å‰ç‚º {transaction_discount}%")
        print(f"4. è­‰äº¤ç¨…è¨­å®šï¼Œç›®å‰ç‚º {trading_tax}%")
        print("5. åƒ¹å·®åœæè¨­å®š")
        print("6. åœæå†é€²å ´è¨­å®š")
        print("0. è¿”å›ä¸»é¸å–®")
        choice = input("è«‹è¼¸å…¥é¸é …ï¼š")
        if choice == "1":
            set_capital_per_stock()
        elif choice == "2":
            transaction_fee = float(input("è«‹è¼¸å…¥æ‰‹çºŒè²»ï¼ˆ%ï¼‰ï¼š"))
            save_settings()
        elif choice == "3":
            transaction_discount = float(input("è«‹è¼¸å…¥æ‰‹çºŒè²»æŠ˜æ•¸ï¼ˆ%ï¼‰ï¼š"))
            save_settings()
        elif choice == "4":
            trading_tax = float(input("è«‹è¼¸å…¥è­‰äº¤ç¨…ï¼ˆ%ï¼‰ï¼š"))
            save_settings()
        elif choice == "5":
            price_gap_stop_loss_menu()
        elif choice == "6":
            stop_loss_reentry_menu()
        elif choice == "0":
            main_menu()
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

def stop_loss_reentry_menu():
    global allow_reentry_after_stop_loss
    while True:
        status = "é–‹å•Ÿ" if allow_reentry_after_stop_loss else "é—œé–‰"
        print(f"\nç›®å‰ç‚º({status}åœæå¾Œé€²å ´)")
        print("1.é–‹å•Ÿåœæå¾Œé€²å ´")
        print("2.é—œé–‰åœæå¾Œé€²å ´")
        print("3.è¿”å›ä¸Šä¸€é ")
        choice = input("è«‹è¼¸å…¥é¸é …ï¼š")
        if choice == '1':
            allow_reentry_after_stop_loss = True
            print("å·²é–‹å•Ÿåœæå¾Œé€²å ´åŠŸèƒ½")
            save_settings()
        elif choice == '2':
            allow_reentry_after_stop_loss = False
            print("å·²é—œé–‰åœæå¾Œé€²å ´åŠŸèƒ½")
            save_settings()
        elif choice == '3':
            settings_menu()
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥")

def price_gap_stop_loss_menu():
    global below_50, price_gap_50_to_100, price_gap_100_to_500, price_gap_500_to_1000, price_gap_above_1000
    while True:
        print(f"1. 50å…ƒä»¥ä¸‹è‚¡ç¥¨åœæåƒ¹å·®ï¼Œç›®å‰ç‚º {below_50} å…ƒ")
        print(f"2. 50~100å…ƒè‚¡ç¥¨åœæåƒ¹å·®ï¼Œç›®å‰ç‚º {price_gap_50_to_100} å…ƒ")
        print(f"3. 100~500å…ƒè‚¡ç¥¨åœæåƒ¹å·®ï¼Œç›®å‰ç‚º {price_gap_100_to_500} å…ƒ")
        print(f"4. 500~1000å…ƒè‚¡ç¥¨åœæåƒ¹å·®ï¼Œç›®å‰ç‚º {price_gap_500_to_1000} å…ƒ")
        print(f"5. 1000å…ƒä»¥ä¸Šè‚¡ç¥¨åœæåƒ¹å·®ï¼Œç›®å‰ç‚º {price_gap_above_1000} å…ƒ")
        print("6. è¿”å›ä¸Šä¸€é ")
        choice = input("è«‹é¸æ“‡è¦è¨­å®šçš„é …ç›®ï¼š")
        if choice == "1":
            below_50 = float(input("è«‹è¼¸å…¥50å…ƒä»¥ä¸‹è‚¡ç¥¨çš„åœæåƒ¹å·®ï¼š"))
        elif choice == "2":
            price_gap_50_to_100 = float(input("è«‹è¼¸å…¥50~100å…ƒè‚¡ç¥¨çš„åœæåƒ¹å·®ï¼š"))
        elif choice == "3":
            price_gap_100_to_500 = float(input("è«‹è¼¸å…¥100~500å…ƒè‚¡ç¥¨çš„åœæåƒ¹å·®ï¼š"))
        elif choice == "4":
            price_gap_500_to_1000 = float(input("è«‹è¼¸å…¥500~1000å…ƒè‚¡ç¥¨çš„åœæåƒ¹å·®ï¼š"))
        elif choice == "5":
            price_gap_above_1000 = float(input("è«‹è¼¸å…¥1000å…ƒä»¥ä¸Šè‚¡ç¥¨çš„åœæåƒ¹å·®ï¼š"))
        elif choice == "6":
            break
        else:
            print("ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡è©¦ã€‚")
        save_settings()

def simulate_trading_menu():
    matrix_dict_analysis = load_matrix_dict_analysis()
    if not matrix_dict_analysis:
        print("æ²’æœ‰æ—ç¾¤è³‡æ–™ï¼Œè«‹å…ˆç®¡ç†æ—ç¾¤ã€‚")
        return

    while True:
        print("è«‹é¸æ“‡æ“ä½œï¼š")
        print("1. åˆ†æå–®ä¸€æ—ç¾¤")
        print("2. åˆ†æå…¨éƒ¨æ—ç¾¤")
        print("0. è¿”å›ä¸»é¸å–®")
        choice = input("è«‹è¼¸å…¥é¸é …ç·¨è™Ÿï¼š")

        if choice == '1':
            group_name = input("è«‹è¼¸å…¥è¦åˆ†æçš„æ—ç¾¤åç¨±ï¼š")
            if group_name not in matrix_dict_analysis:
                print("æ²’æœ‰æ­¤æ—ç¾¤è³‡æ–™")
                continue

            try:
                wait_minutes = int(input("è«‹è¼¸å…¥ç­‰å¾…æ™‚é–“ï¼ˆåˆ†é˜ï¼‰ï¼š"))
            except ValueError:
                print("ç­‰å¾…æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸ã€‚")
                continue

            hold_minutes_input = input("è«‹è¼¸å…¥æŒæœ‰æ™‚é–“ï¼ˆåˆ†é˜ï¼Œè¼¸å…¥ 'F' ä»£è¡¨æŒæœ‰åˆ°13:30å¼·åˆ¶å‡ºå ´ï¼‰ï¼š")
            if hold_minutes_input.upper() == 'F':
                hold_minutes = None
            else:
                try:
                    hold_minutes = int(hold_minutes_input)
                except ValueError:
                    print("æŒæœ‰æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸æˆ– 'F'ã€‚")
                    continue

            disposition_stocks = load_disposition_stocks()
            symbols_to_analyze = matrix_dict_analysis[group_name]
            symbols_to_analyze = [symbol for symbol in symbols_to_analyze if symbol not in disposition_stocks]
            if len(symbols_to_analyze) == 0:
                print(f"{group_name} ä¸­æ²’æœ‰å¯ä¾›åˆ†æçš„è‚¡ç¥¨ã€‚")
                continue

            daily_kline_data, intraday_kline_data = load_kline_data()

            stock_data_collection = initialize_stock_data(symbols_to_analyze, daily_kline_data, intraday_kline_data)
            if not stock_data_collection:
                print("ç„¡æ³•ç²å–æœ‰æ•ˆçš„ä¸€åˆ† K è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œåˆ†æ")
                continue

            total_profit, avg_profit_rate = process_group_data(stock_data_collection, wait_minutes, hold_minutes, matrix_dict_analysis, verbose=True)

            print(f"\næ¨¡æ“¬äº¤æ˜“å®Œæˆï¼Œç¸½åˆ©æ½¤ï¼š{int(total_profit) if total_profit is not None else 0} å…ƒï¼Œå¹³å‡å ±é…¬ç‡ï¼š{avg_profit_rate if avg_profit_rate is not None else 0:.2f}%\n")

        elif choice == '2':
            try:
                wait_minutes = int(input("è«‹è¼¸å…¥ç­‰å¾…æ™‚é–“ï¼ˆåˆ†é˜ï¼‰ï¼š"))
            except ValueError:
                print("ç­‰å¾…æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸ã€‚")
                continue

            hold_minutes_input = input("è«‹è¼¸å…¥æŒæœ‰æ™‚é–“ï¼ˆåˆ†é˜ï¼Œè¼¸å…¥ 'F' ä»£è¡¨æŒæœ‰åˆ°13:30å¼·åˆ¶å‡ºå ´ï¼‰ï¼š")
            if hold_minutes_input.upper() == 'F':
                hold_minutes = None
            else:
                try:
                    hold_minutes = int(hold_minutes_input)
                except ValueError:
                    print("æŒæœ‰æ™‚é–“å¿…é ˆæ˜¯æ•´æ•¸æˆ– 'F'ã€‚")
                    continue

            day_total_profit = 0
            day_avg_profit_rates = []

            for group_name in matrix_dict_analysis.keys():
                print(f"\næ­£åœ¨åˆ†ææ—ç¾¤ï¼š{group_name}")

                disposition_stocks = load_disposition_stocks()
                symbols_to_analyze = matrix_dict_analysis[group_name]
                symbols_to_analyze = [symbol for symbol in symbols_to_analyze if symbol not in disposition_stocks]
                if len(symbols_to_analyze) == 0:
                    print(f"{group_name} ä¸­æ²’æœ‰å¯ä¾›åˆ†æçš„è‚¡ç¥¨ã€‚")
                    continue

                daily_kline_data, intraday_kline_data = load_kline_data()

                stock_data_collection = initialize_stock_data(symbols_to_analyze, daily_kline_data, intraday_kline_data)
                if not stock_data_collection:
                    print(f"ç„¡æ³•ç²å– {group_name} çš„æœ‰æ•ˆä¸€åˆ† K è³‡æ–™ï¼Œè·³éã€‚")
                    continue

                total_profit, avg_profit_rate = process_group_data(stock_data_collection, wait_minutes, hold_minutes, matrix_dict_analysis, verbose=True)

                if total_profit is not None and avg_profit_rate is not None:
                    day_total_profit += total_profit
                    day_avg_profit_rates.append(avg_profit_rate)
                else:
                    pass

            if day_avg_profit_rates:
                day_avg_profit_rate = sum(day_avg_profit_rates) / len(day_avg_profit_rates)
            else:
                day_avg_profit_rate = 0.0

            if day_total_profit > 0:
                print(f"{RED}=" * 50)
                print(f"{RED}\nç•¶æ—¥ç¸½åˆ©æ½¤ï¼š{int(day_total_profit)} å…ƒ{RESET}")
                print(f"{RED}ç•¶æ—¥å ±é…¬ç‡ï¼š{day_avg_profit_rate:.2f}%\n{RESET}")
                print(f"{RED}=" * 50)
            elif day_total_profit < 0:
                print(f"{GREEN}=" * 50)
                print(f"{GREEN}\nç•¶æ—¥ç¸½åˆ©æ½¤ï¼š{int(day_total_profit)} å…ƒ{RESET}")
                print(f"{GREEN}ç•¶æ—¥å ±é…¬ç‡ï¼š{day_avg_profit_rate:.2f}%\n{RESET}")
                print(f"{GREEN}=" * 50)
            else:
                print("=" * 50)
                print(f"\nç•¶æ—¥ç¸½åˆ©æ½¤ï¼š{int(day_total_profit)} å…ƒ")
                print(f"ç•¶æ—¥å ±é…¬ç‡ï¼š{day_avg_profit_rate:.2f}%\n")
                print("=" * 50)

        elif choice == '0':
            break
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")

def display_disposition_stocks():
    disposition_file = 'Disposition.json'
    try:
        with open(disposition_file, 'r', encoding='utf-8') as f:
            disposition_data = json.load(f)
            if isinstance(disposition_data, list):
                stock_codes = disposition_data
            elif isinstance(disposition_data, dict):
                stock_codes = disposition_data.get("stock_codes", [])
            else:
                print(f"éŒ¯èª¤ï¼š{disposition_file} æ–‡ä»¶æ ¼å¼ä¸æ­£ç¢ºã€‚")
                return
    except FileNotFoundError:
        print(f"éŒ¯èª¤ï¼šç„¡æ³•æ‰¾åˆ° {disposition_file} æ–‡ä»¶ã€‚")
        return
    except json.JSONDecodeError:
        print(f"éŒ¯èª¤ï¼š{disposition_file} æ–‡ä»¶æ ¼å¼ä¸æ­£ç¢ºã€‚")
        return

    if not stock_codes:
        print(f"{disposition_file} ä¸­æ²’æœ‰ä»»ä½•è‚¡ç¥¨ä»£è™Ÿã€‚")
        return

    items_per_page = 10
    total_items = len(stock_codes)
    total_pages = (total_items + items_per_page - 1) // items_per_page
    current_page = 1

    while True:
        start_idx = (current_page - 1) * items_per_page
        end_idx = start_idx + items_per_page
        page_items = stock_codes[start_idx:end_idx]

        print("\n" + "=" * 50)
        print(f"{disposition_file} è‚¡ç¥¨ä»£è™Ÿåˆ—è¡¨ - ç¬¬ {current_page} é  / å…± {total_pages} é ")
        print("=" * 50)
        for idx, code in enumerate(page_items, start=1 + start_idx):
            print(f"{idx}. {code}")
        print("=" * 50)
        if total_pages == 1:
            print("å·²é¡¯ç¤ºæ‰€æœ‰è‚¡ç¥¨ä»£è™Ÿã€‚")
            break

        print("å°èˆªé¸é …ï¼š")
        if current_page > 1:
            print("P - ä¸Šä¸€é ")
        if current_page < total_pages:
            print("N - ä¸‹ä¸€é ")
        print("0 - è¿”å›ä¸»é¸å–®")

        choice = input("è«‹è¼¸å…¥é¸é …ï¼ˆN/P/0ï¼‰ï¼š").strip().upper()

        if choice == 'N' and current_page < total_pages:
            current_page += 1
        elif choice == 'P' and current_page > 1:
            current_page -= 1
        elif choice == '0':
            break
        else:
            print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")

def set_capital_per_stock():
    global capital_per_stock
    capital_per_stock = int(input("è«‹è¼¸å…¥æ¯æª”æŠ•å…¥è³‡æœ¬é¡ï¼ˆè¬å…ƒï¼‰ï¼š"))
    print(f"æ¯æª”æŠ•å…¥è³‡æœ¬é¡å·²è¨­å®šç‚ºï¼š{capital_per_stock} è¬å…ƒ")
    save_settings()

def maximize_profit_analysis():
    print("é€²å…¥æ¥µå¤§åŒ–åˆ©æ½¤æ¨¡å¼...")
    
    matrix_dict_analysis = load_matrix_dict_analysis()
    if not matrix_dict_analysis:
        print("æ²’æœ‰æ—ç¾¤è³‡æ–™ï¼Œè«‹å…ˆç®¡ç†æ—ç¾¤ã€‚")
        return

    group_name = input("è«‹è¼¸å…¥è¦åˆ†æçš„æ—ç¾¤åç¨±ï¼š")
    
    if group_name not in matrix_dict_analysis:
        print("æ²’æœ‰æ­¤æ—ç¾¤è³‡æ–™")
        return
    wait_minutes_start = int(input("è«‹è¼¸å…¥ç­‰å¾…æ™‚é–“èµ·å§‹å€¼ï¼ˆåˆ†é˜ï¼‰ï¼š"))
    wait_minutes_end = int(input("è«‹è¼¸å…¥ç­‰å¾…æ™‚é–“çµæŸå€¼ï¼ˆåˆ†é˜ï¼‰ï¼š"))
    hold_minutes_start = int(input("è«‹è¼¸å…¥æŒæœ‰æ™‚é–“èµ·å§‹å€¼ï¼ˆåˆ†é˜ï¼Œè¼¸å…¥0ä»£è¡¨Fï¼‰ï¼š"))
    hold_minutes_end = int(input("è«‹è¼¸å…¥æŒæœ‰æ™‚é–“çµæŸå€¼ï¼ˆåˆ†é˜ï¼Œè¼¸å…¥0ä»£è¡¨Fï¼‰ï¼š"))

    wait_minutes_range = range(wait_minutes_start, wait_minutes_end + 1)
    hold_minutes_range = range(hold_minutes_start, hold_minutes_end + 1)

    disposition_stocks = load_disposition_stocks()
    symbols_to_analyze = matrix_dict_analysis[group_name]
    symbols_to_analyze = [symbol for symbol in symbols_to_analyze if symbol not in disposition_stocks]
    if len(symbols_to_analyze) == 0:
        print(f"{group_name} ä¸­æ²’æœ‰å¯ä¾›åˆ†æçš„è‚¡ç¥¨ã€‚")
        return

    daily_kline_data, intraday_kline_data = load_kline_data()

    stock_data_collection = initialize_stock_data(symbols_to_analyze, daily_kline_data, intraday_kline_data)
    if not stock_data_collection:
        print("ç„¡æ³•ç²å–æœ‰æ•ˆçš„ä¸€åˆ† K è³‡æ–™ï¼Œç„¡æ³•é€²è¡Œåˆ†æ")
        return

    results_df = pd.DataFrame(columns=['ç­‰å¾…æ™‚é–“', 'æŒæœ‰æ™‚é–“', 'ç¸½åˆ©æ½¤', 'å¹³å‡å ±é…¬ç‡'])
    results_df = results_df.astype({
        'ç­‰å¾…æ™‚é–“': 'int',
        'æŒæœ‰æ™‚é–“': 'object',
        'ç¸½åˆ©æ½¤': 'float',
        'å¹³å‡å ±é…¬ç‡': 'float'
    })

    for wait_minutes in wait_minutes_range:
        for hold_minutes in hold_minutes_range:
            hold_minutes_value = None if hold_minutes == 0 else hold_minutes
            print(f"æ­£åœ¨åˆ†æï¼šç­‰å¾…æ™‚é–“ {wait_minutes} åˆ†é˜ã€æŒæœ‰æ™‚é–“ {'F' if hold_minutes_value is None else hold_minutes_value} åˆ†é˜")
            
            total_profit, avg_profit_rate = process_group_data(
                stock_data_collection, wait_minutes, hold_minutes_value, matrix_dict_analysis, verbose=False)
            
            if total_profit is None:
                total_profit = 0.0
            if avg_profit_rate is None:
                avg_profit_rate = 0.0
            
            new_row = pd.DataFrame([{
                'ç­‰å¾…æ™‚é–“': wait_minutes,
                'æŒæœ‰æ™‚é–“': 'F' if hold_minutes_value is None else hold_minutes_value,
                'ç¸½åˆ©æ½¤': float(total_profit),
                'å¹³å‡å ±é…¬ç‡': float(avg_profit_rate)
            }])
            results_df = pd.concat([results_df, new_row], ignore_index=True)

    if results_df.empty:
        print("æ¨¡æ“¬çµæœç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œå¾ŒçºŒåˆ†æã€‚")
        return

    max_profit = results_df['ç¸½åˆ©æ½¤'].max()
    min_profit = results_df['ç¸½åˆ©æ½¤'].min()
    best_combination = results_df.loc[results_df['ç¸½åˆ©æ½¤'].idxmax()]

    print("\nåˆ©æ½¤æœ€å¤§çš„çµ„åˆï¼š")
    print(f"ç­‰å¾…æ™‚é–“ï¼š{best_combination['ç­‰å¾…æ™‚é–“']} åˆ†é˜ï¼ŒæŒæœ‰æ™‚é–“ï¼š{best_combination['æŒæœ‰æ™‚é–“']} åˆ†é˜ï¼Œç¸½åˆ©æ½¤ï¼š{int(best_combination['ç¸½åˆ©æ½¤'])} å…ƒï¼Œå¹³å‡å ±é…¬ç‡ï¼š{best_combination['å¹³å‡å ±é…¬ç‡']:.2f}%\n")

    pivot_df = results_df.pivot(index='ç­‰å¾…æ™‚é–“', columns='æŒæœ‰æ™‚é–“', values='ç¸½åˆ©æ½¤')

    formatted_pivot_df = pivot_df.copy()
    for col in formatted_pivot_df.columns:
        if col != 'ç­‰å¾…æ™‚é–“':
            formatted_pivot_df[col] = formatted_pivot_df[col].apply(lambda x: f"{int(x):,}" if pd.notnull(x) else "")

    formatted_pivot_df_reset = formatted_pivot_df.reset_index()

    print("æ¨¡æ“¬çµæœï¼š")
    print(tabulate(formatted_pivot_df_reset, headers='keys', tablefmt='psql', showindex=False))

    try:
        with pd.ExcelWriter('æ¨¡æ“¬çµæœ.xlsx', engine='openpyxl') as writer:
            pivot_df.to_excel(writer, sheet_name='æ¨¡æ“¬çµæœ', index=True)
            workbook = writer.book
            worksheet = writer.sheets['æ¨¡æ“¬çµæœ']
            
            max_profit = pivot_df.max().max()
            min_profit = pivot_df.min().min()

            max_fill = PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid')
            min_fill = PatternFill(start_color='C6EFCE', end_color='C6EFCE', fill_type='solid')

            for row in worksheet.iter_rows(min_row=2, min_col=2):
                for cell in row:
                    if cell.value == max_profit:
                        cell.fill = max_fill
                    elif cell.value == min_profit:
                        cell.fill = min_fill
        print("\næ¨¡æ“¬çµæœå·²æˆåŠŸå¯«å…¥ 'æ¨¡æ“¬çµæœ.xlsx'ã€‚")
    except Exception as e:
        print(f"\nå¯«å…¥ Excel æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

def manage_groups():
    current_page = 0
    page_size = 5
    groups = load_matrix_dict_analysis()
    total_pages = (len(groups) + page_size - 1) // page_size
    total_page = 1

    def display_page(page):
        load_twse_name_map()                     # â† ç¢ºä¿å·²è¼‰å…¥å°ç…§è¡¨
        start = page * page_size
        end   = start + page_size
        if total_pages == 0:
            print("=" * 50)
            print(f"æ—ç¾¤åŠå€‹è‚¡åˆ—è¡¨ - ç¬¬ {page + 1} é  / å…± {total_page} é ")
            print("=" * 50)
        else:
            print("=" * 50)
            print(f"æ—ç¾¤åŠå€‹è‚¡åˆ—è¡¨ - ç¬¬ {page + 1} é  / å…± {total_pages} é ")
            print("=" * 50)
        for idx, (group, stocks) in enumerate(list(groups.items())[start:end], start=1):
            print(f"æ—ç¾¤: {group}")
            if stocks:
                for s_idx, code in enumerate(stocks, start=1):
                    cname = get_stock_name(code)
                    print(f"  {str(s_idx).rjust(2)}. {code:<6} {cname}")
            else:
                print("  (æ­¤æ—ç¾¤ç›®å‰æ²’æœ‰å€‹è‚¡)")
            print("-" * 50)
        print("=" * 50)
        if current_page == total_pages - 1:
            print("å·²é¡¯ç¤ºæ‰€æœ‰æ—ç¾¤åŠå€‹è‚¡ã€‚")
        print("=" * 50)

    while True:
        display_page(current_page)
        print("\nPï¼šä¸Šä¸€é ã€Qï¼šä¸‹ä¸€é ã€1ï¼šæ–°å¢æ—ç¾¤/å€‹è‚¡ï¼›ã€2ï¼šåˆªé™¤æ—ç¾¤/å€‹è‚¡ã€0ï¼šè¿”å›ä¸»é¸å–®")
        choice = input("è«‹é¸æ“‡æ“ä½œ: ")

        if choice == "P" or "p":
            if current_page > 0:
                current_page -= 1
            else:
                print("å·²ç¶“æ˜¯ç¬¬ä¸€é ï¼")
        elif choice == "Q" or "q":
            if current_page < total_pages - 1:
                current_page += 1
            else:
                print("å·²ç¶“æ˜¯æœ€å¾Œä¸€é ï¼")
        elif choice == "1":
            add_group_or_stock(groups)
        elif choice == "2":
            delete_group_or_stock(groups)
        elif choice == "0":
            save_matrix_dict(groups)
            break
        else:
            print("ç„¡æ•ˆé¸é …ï¼Œè«‹é‡æ–°é¸æ“‡ã€‚")

def add_group_or_stock(groups):
    print("\n==============================")
    print("1ï¼šæ–°å¢æ—ç¾¤ã€2ï¼šæ–°å¢æ—ç¾¤ä¸­çš„å€‹è‚¡ã€3ï¼šè¿”å›é¸å–®")
    print("\n==============================")
    choice = input("è«‹é¸æ“‡æ“ä½œ: ").strip()

    if choice == "1":
        new_group = input("è¼¸å…¥æ–°æ—ç¾¤åç¨±: ").strip()
        if not new_group:
            print("æ—ç¾¤åç¨±ä¸èƒ½ç‚ºç©ºã€‚")
            add_group_or_stock(groups)
        if new_group in groups:
            print(f"æ—ç¾¤ '{new_group}' å·²å­˜åœ¨ã€‚")
        else:
            groups[new_group] = []
            print(f"æ—ç¾¤ '{new_group}' æ–°å¢æˆåŠŸã€‚")
    
    elif choice == "2":
        group_name = input("è¼¸å…¥è¦æ–°å¢å€‹è‚¡çš„æ—ç¾¤åç¨±: ").strip()
        if not group_name:
            print("æ—ç¾¤åç¨±ä¸èƒ½ç‚ºç©ºã€‚")
            add_group_or_stock(groups)
        if group_name in groups:
            current_stocks = groups[group_name]
            print(f"\n==============================")
            print(f"æ—ç¾¤ '{group_name}' ä¸­ç›®å‰çš„å€‹è‚¡:")
            if current_stocks:
                for idx, stock in enumerate(current_stocks, start=1):
                    print(f"  {str(idx).rjust(2)}. {stock}")
            else:
                print("  ç„¡")
            print("==============================\n")
            
            print(f"é–‹å§‹æ–°å¢å€‹è‚¡åˆ°æ—ç¾¤ '{group_name}'ã€‚")
            print("è«‹è¼¸å…¥å€‹è‚¡ä»£è™Ÿï¼Œè¼¸å…¥ 'Q' ä»¥é€€å‡ºæ–°å¢æ¨¡å¼ã€‚")
            
            while True:
                new_stock = input("è¼¸å…¥å€‹è‚¡ä»£è™Ÿ (æˆ– 'Q' é€€å‡º): ").strip()
                if new_stock.upper() == "Q":
                    print("é€€å‡ºæ–°å¢å€‹è‚¡æ¨¡å¼ã€‚")
                    break
                elif not new_stock:
                    print("è¼¸å…¥ç„¡æ•ˆï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")
                    continue
                elif new_stock in groups[group_name]:
                    print(f"å€‹è‚¡ '{new_stock} {get_stock_name(new_stock)}' å·²å­˜åœ¨æ–¼æ—ç¾¤ '{group_name}' ä¸­ã€‚")
                else:
                    groups[group_name].append(new_stock)
                    print(f"å€‹è‚¡ '{new_stock} {get_stock_name(new_stock)}' å·²æ–°å¢è‡³æ—ç¾¤ '{group_name}'ã€‚")
        else:
            print(f"æ—ç¾¤ '{group_name}' ä¸å­˜åœ¨ã€‚")
    
    elif choice == "0":
        print("è¿”å›ä¸»é¸å–®ã€‚")
        manage_groups()

    else:
        print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°é¸æ“‡ã€‚")

def delete_group_or_stock(groups):
    print("\n==============================")
    print("1ï¼šåˆªé™¤æ—ç¾¤ã€2ï¼šåˆªé™¤æ—ç¾¤ä¸­çš„å€‹è‚¡ã€3ï¼šè¿”å›é¸å–®")
    print("\n==============================")
    choice = input("è«‹é¸æ“‡æ“ä½œ: ").strip()

    if choice == "1":
        group_name = input("è¼¸å…¥è¦åˆªé™¤çš„æ—ç¾¤åç¨±: ").strip()
        if not group_name:
            print("æ—ç¾¤åç¨±ä¸èƒ½ç‚ºç©ºã€‚")
            delete_group_or_stock(groups)
        if group_name in groups:
            confirm = input(f"ç¢ºå®šè¦åˆªé™¤æ—ç¾¤ '{group_name}' å—ï¼Ÿ (Y/N): ").strip().upper()
            if confirm == "Y":
                del groups[group_name]
                print(f"æ—ç¾¤ '{group_name}' å·²åˆªé™¤ã€‚")
            else:
                print("å–æ¶ˆåˆªé™¤ã€‚")
        else:
            print(f"æ—ç¾¤ '{group_name}' ä¸å­˜åœ¨ã€‚")

    elif choice == "2":
        group_name = input("è¼¸å…¥è¦åˆªé™¤å€‹è‚¡çš„æ—ç¾¤åç¨±: ").strip()
        if not group_name:
            print("æ—ç¾¤åç¨±ä¸èƒ½ç‚ºç©ºã€‚")
            delete_group_or_stock(groups)
        if group_name in groups:
            current_stocks = groups[group_name]
            print(f"\n==============================")
            print(f"æ—ç¾¤ '{group_name}' ä¸­ç›®å‰çš„å€‹è‚¡:")
            if current_stocks:
                for idx, stock in enumerate(current_stocks, start=1):
                    print(f"  {str(idx).rjust(2)}. {stock}")
            else:
                print("  ç„¡")
            print("==============================\n")

            if not current_stocks:
                print(f"æ—ç¾¤ '{group_name}' ä¸­ç›®å‰æ²’æœ‰ä»»ä½•å€‹è‚¡ã€‚")
                delete_group_or_stock(groups)

            print(f"é–‹å§‹åˆªé™¤å€‹è‚¡å¾æ—ç¾¤ '{group_name}'ã€‚")
            print("è«‹è¼¸å…¥è¦åˆªé™¤çš„å€‹è‚¡ä»£è™Ÿï¼Œè¼¸å…¥ 'Q' ä»¥é€€å‡ºåˆªé™¤æ¨¡å¼ã€‚")

            while True:
                stock_name = input("è¼¸å…¥å€‹è‚¡ä»£è™Ÿ (æˆ– 'Q' é€€å‡º): ").strip()
                if stock_name.upper() == "Q":
                    print("é€€å‡ºåˆªé™¤å€‹è‚¡æ¨¡å¼ã€‚")
                    break
                elif not stock_name:
                    print("è¼¸å…¥ç„¡æ•ˆï¼Œè«‹é‡æ–°è¼¸å…¥ã€‚")
                    continue
                elif stock_name not in groups[group_name]:
                    print(f"å€‹è‚¡ '{stock_name}' ä¸å­˜åœ¨æ–¼æ—ç¾¤ '{group_name}' ä¸­ã€‚")
                else:
                    confirm = input(f"ç¢ºå®šè¦åˆªé™¤å€‹è‚¡ '{stock_name} {get_stock_name(stock_name)} 'å—ï¼Ÿ (Y/N): ").strip().upper()
                    if confirm == "Y":
                        groups[group_name].remove(stock_name)
                        print(f"å€‹è‚¡ '{stock_name}' å·²å¾æ—ç¾¤ '{group_name}' ä¸­åˆªé™¤ã€‚")
                        if not groups[group_name]:
                            print(f"æ—ç¾¤ '{group_name}' ç¾åœ¨å·²ç¶“æ²’æœ‰ä»»ä½•å€‹è‚¡ã€‚")
                    else:
                        print("å–æ¶ˆåˆªé™¤ã€‚")
        else:
            print(f"æ—ç¾¤ '{group_name}' ä¸å­˜åœ¨ã€‚")

    elif choice == "0":
        print("è¿”å›ä¸»é¸å–®ã€‚")
        manage_groups()

    else:
        print("ç„¡æ•ˆçš„é¸é …ï¼Œè«‹é‡æ–°é¸æ“‡ã€‚")

def main():
    load_settings()
    config = load_config("config.yaml")
    client = RestClient(api_key=config['api_key'])
    matrix_dict_analysis = load_matrix_dict_analysis()
    main_menu()

if __name__ == "__main__":
    '''
    #æ¸¬è©¦ä¸­æ–‡è‚¡ç¥¨åç¨±
    data = fetch_twse_stock_codes(save_json="twse_stocks.json",
                                  save_csv="twse_stocks.csv")
    for code, name in data[:20]:
        print(code, name)
    '''
    ensure_packages(REQUIRED)
    print("é–‹å§‹åŸ·è¡Œç¨‹å¼...")
    main()